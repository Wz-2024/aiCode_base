{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6, 24, 24])\n",
      "torch.Size([10, 10, 22, 22])\n",
      "torch.Size([10, 16, 10, 10])\n",
      "torch.Size([10, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "data=torch.ones(size=(10,3,28,28))\n",
    "conv1=nn.Conv2d(in_channels=3,\n",
    "                    out_channels=6,\n",
    "                    kernel_size=5,\n",
    "                    stride=1,\n",
    "                    padding=0\n",
    "                )\n",
    "\n",
    "conv2=nn.Conv2d(6,10,3)\n",
    "conv3=nn.Conv2d(10,16,5,stride=2,padding=1)\n",
    "conv4=nn.Conv2d(16,3,5,stride=3,padding=2)\n",
    "\n",
    "x=conv1(data)\n",
    "print(x.shape)\n",
    "x=conv2(x)\n",
    "print(x.shape)\n",
    "x=conv3(x)\n",
    "print(x.shape)\n",
    "x=conv4(x)\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NiN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "print(3)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class NiN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(nn.Conv2d(3,192,5,padding=2),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,160,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(160,96,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "                                    ,nn.Dropout(0.25))\n",
    "        self.block2 = nn.Sequential(nn.Conv2d(96,192,5,padding=2),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,192,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,192,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.MaxPool2d(kernel_size=3,stride=2)\n",
    "                                    ,nn.Dropout(0.25))\n",
    "        self.block3 = nn.Sequential(nn.Conv2d(192,192,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,192,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.Conv2d(192,10,1),nn.ReLU(inplace=True)\n",
    "                                    ,nn.AvgPool2d(7,stride=1)\n",
    "                                    ,nn.Softmax(dim=1))\n",
    "    def forward(self,x):\n",
    "        output = self.block3(self.block2(self.block1(x)))\n",
    "        return output\n",
    "data = torch.ones(size=(10,3,32,32))\n",
    "\n",
    "model=NiN()\n",
    "model(data).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cat()函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6191,  0.7683, -0.9812,  0.9117, -1.5129],\n",
      "        [-0.9079,  0.2384, -0.3349, -0.3889,  0.9516]])\n",
      "\n",
      "tensor([[-0.7978,  0.5805,  0.1777],\n",
      "        [ 0.2033,  0.5325,  1.5137]])\n",
      "\n",
      "tensor([[ 1.8078,  0.7524,  1.8993,  1.0485,  0.1140],\n",
      "        [-0.0696,  0.2065, -1.2179, -1.3237, -0.8022],\n",
      "        [-1.2036, -0.3425,  0.5374,  0.5788, -0.0843]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.randn((2,5))\n",
    "b=torch.randn((2,3))#-->2,8\n",
    "c=torch.randn((3,5))#-->5,5\n",
    "print(a)\n",
    "print()\n",
    "print(b) \n",
    "print()\n",
    "print(c)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6191,  0.7683, -0.9812,  0.9117, -1.5129, -0.7978,  0.5805,  0.1777],\n",
      "        [-0.9079,  0.2384, -0.3349, -0.3889,  0.9516,  0.2033,  0.5325,  1.5137]])\n",
      "tensor([[-0.6191,  0.7683, -0.9812,  0.9117, -1.5129],\n",
      "        [-0.9079,  0.2384, -0.3349, -0.3889,  0.9516],\n",
      "        [ 1.8078,  0.7524,  1.8993,  1.0485,  0.1140],\n",
      "        [-0.0696,  0.2065, -1.2179, -1.3237, -0.8022],\n",
      "        [-1.2036, -0.3425,  0.5374,  0.5788, -0.0843]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat([a,b],dim=1))#表示在第1维度上拼在一起\n",
    "print(torch.cat([a,c],dim=0))#表示在第0维度上拼在一起\n",
    "#总结,哪个维度一样,就按照另一个维度拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0295,  0.7706,  0.7189],\n",
      "        [ 1.7642,  1.0481, -1.2241]])\n",
      "tensor([[ 0.3924, -0.2087, -0.5352]])\n",
      "tensor([[ 1.4219,  0.5619,  0.1838],\n",
      "        [ 2.1566,  0.8394, -1.7592]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a=torch.randn(2,3)\n",
    "b=torch.randn(1,3)\n",
    "c=a+b\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (1649640625.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def make_layers(afterconv1:bool=False, num_blocks: int):\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "class Node():\n",
    "    def __init__(self,val):\n",
    "        self.val=val\n",
    "\n",
    "node=Node()\n",
    "n1=node(1)\n",
    "print(type(node))\n",
    "print(type(n1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
