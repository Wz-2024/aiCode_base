{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "torch.backends.cudnn.enabled = True#cuda提供的加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn,optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms as T\n",
    "from torchvision import models as m\n",
    "from torch.utils.data import DataLoader\n",
    "#画图,辅助\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas\n",
    "import datetime\n",
    "import gc\n",
    "#设置全局随机数种子\n",
    "torch.manual_seed(112)\n",
    "random.seed(112)\n",
    "np.random.seed(112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(73257, 3, 32, 32)\n",
      "<class 'torchvision.datasets.svhn.SVHN'>\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(\"/data_disk/dyy/python_projects/bili_dif/data_SVHN\"))\n",
    "\n",
    "#定义一些数据增强的Compose\n",
    "trainT=T.Compose([\n",
    "    T.RandomCrop(28),#裁剪尺寸\n",
    "    T.RandomRotation(degrees=[-30,30]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "]\n",
    ")\n",
    "testT=T.Compose([\n",
    "    T.CenterCrop(28),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])   \n",
    "])\n",
    "\n",
    "train=torchvision.datasets.SVHN(\n",
    "    root='/data_disk/dyy/python_projects/bili_dif/data_SVHN',\n",
    "    split='train',\n",
    "    download=False,\n",
    "    transform=trainT\n",
    ")\n",
    "test=torchvision.datasets.SVHN(\n",
    "    root='/data_disk/dyy/python_projects/bili_dif/data_SVHN',\n",
    "    split='test',\n",
    "    download=False,\n",
    "    transform=testT\n",
    ")\n",
    "print(train.data.shape)\n",
    "print(type(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train[2][1]#第一个索引表示第几个样本,每个样本有两个元素,第一个是图像,第二个是标签\n",
    "np.unique(train.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机抽(图,标签)的工具函数\n",
    "def plotsample(data):#只能接受Tensor格式\n",
    "    fig,axs=plt.subplots(1,5,figsize=(10,10))\n",
    "    for i in range(5):\n",
    "        num=random.randint(0,len(data)-1)#roll五个数\n",
    "        npimg=torchvision.utils.make_grid(data[num][0]).numpy()#make_grid提升通道数\n",
    "        nplabel=data[num][1]#标签提出来\n",
    "        axs[i].imshow(np.transpose(npimg,(1,2,0)))\n",
    "        axs[i].set_title(nplabel)\n",
    "        axs[i].axis('off') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..0.2870589].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..1.2456646].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..0.33934647].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..0.7925056].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-2.117904..0.7925056].\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAACvCAYAAACVbcM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh/klEQVR4nO3df3Ac9Znn8UenGaQxjEAKlsGuWHZsEh+WA6YwPpMK4cIWhrBs2OJ3hQNqk3XVHXFyl+QqlQskF1JhkyKVwrnsHXGOQFgnYReygfDj1oRsEhPsBftWsNiLYmRjOZaMZRgJjcsjZUbo/riN7/r7fMCNpK9mpHm/qvijH3paX416uvvr6U8/DePj4+MGAAAAAFPsX1V7AAAAAABmJyYbAAAAAKJgsgEAAAAgCiYbAAAAAKJgsgEAAAAgCiYbAAAAAKJgsgEAAAAgCiYbAAAAAKJgsgEAAAAgCiYbAAAAAKJgspHC9u3b7ZOf/KQtX77cTjzxRFu4cKFdc801tnv37moPDXXiyJEj9uUvf9kuueQSa2trs4aGBrvvvvuqPSzUCfY/VNvo6Kh9/vOft/nz51sul7PVq1fbz3/+82oPC3Xqa1/7mjU0NFhnZ2e1hzIjMNlI4Rvf+Ib95Cc/sYsuusg2bNhg69atsy1bttg555xjO3furPbwUAdee+01u/322+2ll16ys846q9rDQZ1h/0O13Xzzzfatb33LPvaxj9mGDRussbHRPvKRj9hvfvObag8NdebAgQN2xx132IknnljtocwYDePj4+PVHkSt27p1q5177rl2wgknHKu9/PLLtmLFCrvqqqts06ZNVRwd6sHo6KgNDg7aaaedZjt27LBVq1bZvffeazfffHO1h4Y6wP6Hanruueds9erVduedd9rnPvc5MzMbGRmxzs5Oa29vt61bt1Z5hKgn1113nR0+fNjGxsbstdde4x+dU+CbjRTOP//8xETDzOyMM86w5cuX20svvVSlUaGeNDU12WmnnVbtYaBOsf+hmh566CFrbGy0devWHas1Nzfbxz/+cdu2bZv97ne/q+LoUE+2bNliDz30kN11113VHsqMwmRjgsbHx+3QoUN26qmnVnsoAADMWl1dXfbe977XWlpaEvXzzjvPzMyef/75KowK9WZsbMzWr19vn/jEJ2zFihXVHs6Mkqn2AGaqH/7wh9bX12e33357tYcCAMCsdfDgQTv99NNd/Q+1/v7+6R4S6tDdd99tvb299tRTT1V7KDMO32xMQHd3t91yyy22Zs0au+mmm6o9HAAAZq1SqWRNTU2u3tzcfOz/AzG9/vrr9qUvfcluu+02mzt3brWHM+Mw2XiHXn31Vbvsssvs5JNPPnYfKQAAiCOXy9no6Kirj4yMHPv/QEy33nqrtbW12fr166s9lBmJ26jegTfeeMMuvfRSGxoasqefftrmz59f7SEBADCrnX766dbX1+fqBw8eNDPjXIyoXn75Zdu4caPdddddiVv2RkZGrFwu2759+6ylpcXa2tqqOMraxjcbKY2MjNjll19uu3fvtscee8zOPPPMag8JAIBZ7+yzz7bdu3fb8PBwov7ss88e+/9ALH19ffbmm2/apz71KVu8ePGx/5599lnbvXu3LV68mPzucfDNRgpjY2N27bXX2rZt2+yRRx6xNWvWVHtIAADUhauuusq++c1v2saNG4/12RgdHbV7773XVq9ebe9+97urPELMZp2dnfbTn/7U1W+99VYrFou2YcMGW7JkSRVGNnMw2Ujhs5/9rP3sZz+zyy+/3AqFgmvid8MNN1RpZKgn3/nOd2xoaOjY17iPPvqoHThwwMzM1q9fbyeffHI1h4dZjv0P1bJ69Wq7+uqr7Qtf+IINDAzY0qVL7Qc/+IHt27fP7rnnnmoPD7PcqaeealdccYWr/6HXhvp/SKKDeAoXXnih/frXv37L/89biOmwaNEi6+3tlf/vlVdesUWLFk3vgFBX2P9QTSMjI3bbbbfZpk2bbHBw0N7//vfbV7/6VVu7dm21h4Y6deGFF9JBPCUmGwAAAACiICAOAAAAIAomGwAAAACiYLIBAAAAIAomGwAAAACiYLIBAAAAIAomGwAAAACiSN3Ur6GhIeY4kDBH1I5O+yjSmK4nJ8/0/e+6z/yjq+Xb8onlHTu7Um2rs3OZqzXPy7laR8eCxHKx5HsklMplP66WFlfL5ZKHiox/meUt62q3fHieX3EKTeeTu2f6Pji13uVLTR2+1ub3JefgryY9mmriGIhqqvn976z7fe2FHrHidlErBcvtYh11GTsoaq2+9J6licWGZZ1+6y3+3JoTP7JYCMdqNt43kCzsEX2KjtzpazNI2v2PbzYAAAAARMFkAwAAAEAUTDYAAAAARMFkAwAAAEAUqQPimE4+aIvatPF7PhzVHYbCzOzu7//Y1cpB+K19ft6t0z9QcLVM3u8f7ZU2V2trDYJtYrfK5Xz4LSvS35UwqJf1Yx0RYfMNTx5ytU9fHDc0jmnQ6P+Gc5b6WvgQhELJhyjLB9W/eb054aEBqCEqTX2KqA2p8HcYqJ7MJWvRl0qVxOJ4ZcStUhn2J86S+J3G/aHNrBIsiwermN0kav4awmw4HIVYxz+IplbwzQYAAACAKJhsAAAAAIiCyQYAAACAKJhsAAAAAIiCgHhNekPUTgiWfz8dA6kbzzx9/C6Yg2E+y8ye2Ow7gm7v8p3Aj+5/WGwxGfDq2+9D3mY+wL2r3QfWdnX55Fm41vJVS9w6+Xl+W8Vh8Yu6zYfJN7NyxR9OmjM+SI5ZQPxZm0UtH9TK4oxTUJ3HR1+Z2LhQs1bO9UHY1lxyBxkp++PKwECfq/WMPTp1A0NcOf83tTZ/XrMh9eLw2CCOFU3ioDK6TWxLHKByzcnlTMpL4or/nRqy/lw6nuphPyoMLjqNu8t1Ndb3p9yWusaMi282AAAAAETBZAMAAABAFEw2AAAAAEQRP7PReKavjfWIFckgvD1x3yOO67nnfRajnKb5jpkVg356/eLWym1bX3S1rh1bUo7u2ZTrJR39B98ob865a/2Kwf2nedHALyfupy2WxJsRZjbEragjWf+6vLg1d+M2/1lftybMJKG2qQ+Rz/qEt+BXKuJ1LWInOTyxUaEaznCVlsalrnbx2otcLVNJHlgGC76JaX+f3z96ds0R4zj6NmPEtDn3ruTygD9fWUGcYxp9ptA6FiSXwxCYmVlJnJj7l73l8BLag0ak4lg0Piya3MrmfOKkGDYxHVXXcSIjaeI9szDTqfKQ4lhqqlkimQ0AAAAAswSTDQAAAABRMNkAAAAAEAWTDQAAAABRTC4g3nSOr4Uh1OKgeCFh8HfuzWoPoObc/7gPfy8I8l69op+NCi0rg0FWMaMysaWiKKr0mA8+Tpz/mWEOzcx/uHMi/NbaLGodra7WP6AaDyVlVTit5Gt0Ep0FhnyAsdDr/7LFtmQgslwQn5eyCkjCUw9RWClqE3vwxEStPOt6Vzv3X/uAeE6Ee8vBQbZZPMRC1RpskauN2z+/3TAxXfLBcUCdnNQDJtpEU9v2INwcnuDNzCotvjYijjMrfWh8TmtyrEeL6nzuj2uyBXBPt6/t3R4UxDqSes/CALq6kFE1dcZV1yOvH29Qk8I3GwAAAACiYLIBAAAAIAomGwAAAACiYLIBAAAAIIr0Wc2TVvvakT5fGw1DLKoTIvDOfP0B3x32iS2+e/f8tmTH0b0v+mDzuSt8p9IlHb7758BAMkQ1KHblPSoUJkNgaYNhafyTq4zv8sG2h76frKmA+JXXi4Bpxr8XxSDoXRxQQV9fMtExupLx49j498nI3boPN4iNoXaIbs3iIQLlMBw6pIKJdH5Oo+ODt7haLu+7A3c/EVbiBsa7Xtjoap0rvu1qvQP+bz/QuyexPNgnrimEcxeucrXt+9WahManXXj6kFeZ6okm4gQSnipU0+wR8QM6F7hSdr4PoLeG58Sc7/B9tF+c6wpi/PJhMeF66mEY6pjoH7BgFv5OIgzeKN7DsekPgyt8swEAAAAgCiYbAAAAAKJgsgEAAAAgCiYbAAAAAKKYZDNf0bnReoJlH7jBdFLzyZnXjfyXv9jqapu/92NXa3vvhxLLF5zng4RPPrbZ1das8t1Fi4Vk+/HSiAhY/+laV7v3AdVtW9V80HvifDCsIejY29qasnW6+MguCLq77uzzv09FJcQzPpSnOo03+0w6alrKf6caOhB3GHVkWXurq7V3+IddrDrvK4nlv7rrfr+xoR9N2bjMfEi9UBh0tT1dz7nabw8mOyyP206xff97Z61DrKeeUIGoPvrdyD8gOBmJB45YWdQqfl8oiyB2sZw8Fx2tiDB1WZwQD/X6WkE9DCncd9X1sDr5qUvzoNboPxfWJrZ/WAXE54ha3Ad18M0GAAAAgCiYbAAAAACIgskGAAAAgCgmmdkQ98rZ7ye3SUyxmZfPUDZ/74uiut1VCrv/PrH88G61NX8P45anr3e1lqbk8tmiGWAuN0/9AEF91MK5/mT+Vv7e+PEX7k0sf/vrI26d4shVrnbuKtEQKZscf7HoGxjlc82ulhENAv1apg8lqGFiXx1TTa0wVfpFTqq13Tf/yrcEnc+ysQNR/tj2227fxLT3oL/PfTxVbs03ICub2tf8cctscbD8Soqfh7Tm5Pzf/mhP8LfpFwf3rM/y2QL19wuyF92+ka8Ni33hfJ/BlOeYbLD9ssg1VkQ+Q2U7Kj6n5K81/DWEWb+opTiW5sTnWl1mNIr1xo6/+anGNxsAAAAAomCyAQAAACAKJhsAAAAAomCyAQAAACCK9AHxjGqYo2oEshDDsynXm+j+9qCoXZ1Y6h3Y49boaPeNLVtOmS+2dYWrDA+Fgbg+8bp/FLUJKgy70mDBh077B3x4L5c7fsOsTM6/F7mM/5lZy7taKRjG9x/yD5r4s6tOOO4YUE2z42EUterF7f6BGHPn+eZ2ubawNsnnwByXD7MWBnyDMx3qnij1IBrVVG1RsDz9zcxms7xo2no0zFhnVNM9sU+qoPdA8Nq+sGm0mY2JsPZS32jS2n34e7gvaILXJ87B/aIh737VpFftfyH1GfDnQy0Yq/h9LCdqWfFe7BcBfZr6AQAAAJiJmGwAAAAAiILJBgAAAIAomGwAAAAAiCJ9cqzkuw/bXNHxcTgIzoy+wxEhJYJuWvi+pH1PfJfa4dG7k8v7/dy8WL7O1a69/s9cbVe3D4Zt/WVYUaGtyQTEg3BdyXcSffgvNrta4RYfKLvy6pWJ5fnzfWA8LzoVV1QeTmTwKsPJscaOtAIzzpjvyl0s+K7FuSBH2pDxn8vxKRuUmZkPy2bFz4xPHetbg2URlrVfTf1Q6kSrOGcNBBnl8WzFrSMD4kWx3sEw/O0f0mLmH0JiXWK9BeG+YP5EUxAPQpHPRlFnKBHOdm3L06xjJq8FTg8ePCM3JQL0+3eKFQ+IWlx8swEAAAAgCiYbAAAAAKJgsgEAAAAgCiYbAAAAAKKYXA4zzaubwo7iZjaqOiWrjqD4f04LltWbLwJWs+Z9/S/pVmtcklwe+0ux0kRD175DsmrYqSxZucTV9gwkk2eHdqk09X8WtQ2ipv7OryYXh+4X69woat6SoClx/hQfAO393ypc5/fJXMa/aa0LkrVS0W/r4cd5AALq2Ru+JLKxzUE4O1PynyWZeZ1Cmaw6P4lOz1PKPzSlY/mKxHJvjwjQ8hCbVFbc8JyrdQ/4v2kmSC6XXUjfTHbSLql9JgxPix1eObhP/Eix17cF56JmMYaK+rSosaqHIoTjV9tS120plFRn9gluaxrwzQYAAACAKJhsAAAAAIiCyQYAAACAKJhsAAAAAIgifUBchWQKIvAVBsPKqjuiStXOliDzVDhB1ML3ukOss1TUDoma+pvUdvg2u/wKV6uIgNT4QG+ycKQl0oj+r769P3K1X273+/d/+vQdrrZwwYLE8o4X/d9v832PiZ860c+P75Ku9oV8znfZ/crXk12C/3ydX6ckugZXCr67cF6st7Atub18ToTtRAd0oJ4VB/05uFJIhmjLQ77L+NTywfW+w77becd7rnC13r1hd+P/NYlx+HNY764HE8sLlq916/T1fMBvavSZSYxjdiqUfDi73OeP79YdnFMyeb9OiziHDfl9xmx7sNwr1jlP1EQH7iPiuqccnFNaRMC6pM636lyU5qE96iEw6npMhOorwXolNVaxqeiPg0iHbzYAAAAARMFkAwAAAEAUTDYAAAAARDG5pn6qgchocNNYk/oRonbSGb525OUJDWvmU/ffhw2LxH2EjaI2pu7XE/dZppp3+qZ206W860VfnOtzA5YJ9q1T1vl1hsQ9pPbohMalZETeICfuUc1XMsE6YmMnib/pEfVTfUOrdDmcu13l8Vv9PrPiM19JLBdVT6aCv2G0MOzvKV82z99PGzZHVM0SRX9AoK517/efX9ucXPzMp/6DW+Vb31bnhak7Bqp75lvyvjZvYbLZ6aH9UzgEMwtzakVx4GqZN8/Vhqd8HDNfX3e/L+5SmcLgPR7r9KuUzhevU+flsKayEqrRn9qWyHGMBp+Dw+Jl8npJ1VQ+NlxPhioElccIarKhcNpmg9OPbzYAAAAARMFkAwAAAEAUTDYAAAAARMFkAwAAAEAU6QPiohFXqk2q1GubCOoUVXDmXcGyako2lVQzvVppNhi8Z00iADWqGsaoFJEIVrvgUq383n/wRV86fJWvNa5ILi9QzYOmZEBvTfxpNv3dd13tyj++MbG8fKX/XGRu+ZCrPfKg/53Ke78uBjLRRo1+PyoFDRRFP0Wd6s7632l7zx6//SD9/b4237QyX/Wcm/q3meo9NAFQ8kEQe0Q1/4rOPxiidZ4/7wzngoBu5GD2cKHPF4+MxP2hs0V3jyiqWthEUlxmHlENiJVwn1HBb3Xdo2rqteGDEtRJRj1MYaJBb/VZVA2axTVaeHoti2adQ+rv8Yoc2XTjmw0AAAAAUTDZAAAAABAFkw0AAAAAUTDZAAAAABDF5DqIyy0GKZZ2FUZWgRshH3T2LIgAqsrbjKnujirwfHKKcdVKUPpAcjHs1G5mPphlpkNRSq38nm/l1XSrtQW79LDq6qnCY1On+wnf1ffi/+678w6WkiHKgQG/3+byovN4u3/oQmGvaj8+UX/jKj3/I7m//bfBr7h1rr1+patVZJLcf87C9VSn32wu7b6M+AjL1wb/UJN8W3NiuVhU58PYoXF/LsqLa4H+nq7I4wgcEceVUxa4Wnnon6djNDPL2EZRVN27Q+q43Stq6vor7Fqu9mV1GavOO62iFgbC1bWB+plpfm8zn+pW41I1MY5C+JlNG1KvDXyzAQAAACAKJhsAAAAAomCyAQAAACAKJhsAAAAAokgfEM+JVUspgt4DvpOotYhtqe2HGRnVjVz9CiXRBVIGqlOGjmuS6qau5o5vxB5IFX3Hlw6vDgo+/Gdz14rXia729rcTGZRZ45mpVisMqpBc0hLRaPXf37LG1f667b+6Ws8TYW3qQo/Fgv88FQs+1NYq2n43i89xXxAIL1f2uXUGM/51H5bdVxGfOnXU+kMmZiP/nhdLyc9SoSDOwaYenDGV/Paf79rpavm25Ge6sDfagP6FP261i+B631DsccxEKhR9VNQWB8vqGC06uctu5OE+o65nwp9nJs/7Lmxu5gPc+8Q66jwtHlZk6hpCrRdKGUofCwPuaTun1wa+2QAAAAAQBZMNAAAAAFEw2QAAAAAQBZMNAAAAAFG8g4C46gIpXl4ZCQt+nWFRy4ptlYP1ss1+HUmMtSK27zqNz/QOuDN9/FNhe7AsgmLzxf5xWHW6n6AxH8T+6wcfd7Vrb0wG1fMiX/aepctc7fAhFTpTHYHTf7yPL9kB/eiTfgybhte52g03nu9qHUvnu1pzOQzv+TBioZjigRRR8flCrfEdxEeyyWPBwLDqgKzCslNJBFVz/pjR1p48Fqso+9TyAfGcGJfZHFFTYeh6El7bvZXwOK0ezqP+0mm7a4dU2Fz9TdX5MAylp/0dVRhcbd8/FMGbaKhbnQ9rt6s432wAAAAAiILJBgAAAIAomGwAAAAAiGJyN3WL3nnu1nF1K7lSSbFiRdzblhH35pXEtsbUBrkHe/YJcz1/51ep+BzEnA+udLWjT58RVF5ON4SmS13p4ksucLXwVuF83u/LLa3+3tDBYX+v5vrP+UaFm1qS29v+wAa3jtmvRG1iyuIznMn630n8SpYpJe/dzpbFSmn6IyEC9W9SNPCrDcf/nAwUVAO/2A1t/f7Rt+M/ulrHB5ONWZfd8CO3TvemL4rtvzLBcflmuD0vPOxqS8+6Wqz32HG3NbuFTeXMdN4gbL6qmjGrvIG6oAwvUdVxR9VUdkH9zInmcFQOSo0/vB5RmRCVF01zaT7RjEt18M0GAAAAgCiYbAAAAACIgskGAAAAgCiYbAAAAACIIn1A/OAzvnb6B3wtDHGWRCBG5XRyqkFgmtC4WEc18GtUTf1OCwqxQ3OYWr6hldm85OLcVW6NlmW+qdxwV9jcxyx1IDzw4esvc7W+l3wTo+UrVySWBwq+OVF393Ou1rHAB9wLBR/Ca8uHwTPViCit8L0WjRF3POhK/7PsU91nn+df+2/XLk0sZ0v+/WptUY1FgXrmz1kvPvfrxPLKiy5x6xwuXeNqR/f+zdQNK6XBQjLQ2tKhLkn88XriAfF02uf50G6PLQ0q9RYQnydqvmlrOupYrsLN4XlNBbrVv5mr/WgqnzCStsFsmickpb0MD98fte3afXAH32wAAAAAiILJBgAAAIAomGwAAAAAiILJBgAAAIAoJtdBXAlzM5PJ0eSC7osZ0cGyJEJF7aJjZUGsJ7uKY6aYc/GnXa21fUFiOdcugn5buvzG9v54ysZ1eNDvzFde7zuIj5SSgfDBgu9Kmi37j2gu69fLifB3LhMG4lQo7yZRCzvlmpkNBsvq/brIVcZf8O91lwjqtXcEy+KAkJk39YcrpPFmtQeAd6ChI3kMzOT95/5opTY6DefyyXP13HYRQl64wNf2RxrQv+jt6xXVF+P+0JqnOl2rWvj3Ul3G1fvbL2rhueJksU6HqKV9GMqhYFmF/tW/yauwebgtMx/YniPWUZ3HlfBiujY+w2nxzQYAAACAKJhsAAAAAIiCyQYAAACAKJhsAAAAAIhiconLtF3FQ6qreEYMJRcEvSeTh8mKQE826MR8xAdv6zcc+S5Rm8oOnJN39Mk7Xe1Pvv1UspD3DwsoDPgdqbBDhcwOpBhF2IXe7N9c0OlqrW3+vRsMhjEw4Pc/Vevv90G6szv95+cjVyfHUS76QP3jm/7S1XwY3Czd5+AXoibCby/4Bz1sfiHZKX3plR9y65SWqadNiPAoUMfaFwShXXXYLhSmZSzHc2j71sRy61LxEJhWEfadyoB4kz/29/WoALPqXl1PVCd3FW4Oz6/qMlPVVNg83JbamdU5QG1LBdXD7S0W6yjq8/OGqIWBdjUuJU3n8bRPX6oNfLMBAAAAIAomGwAAAACiYLIBAAAAIIr4XbKy4p6+Spr70cz88MTr5PbFpnLiXr/DYROWes1nCCeJDIN6D2tMPpcc9/6Czx8UNqlswfYJ/sRXXeUfuvz9vm1tPjuSyST33W1bfQO8JUv8fbLvO+dsV8vnxH3NleT2n+/q9utMOJ+R9v7lv0253h8llooF3yCpdd4yVwOQlGlJfu4rFXFv9xH1ua++7s0P+2JOjLXpDF8bVffk++NzaN7Spa52aFe9N/BT0jbKS3N9py491fVF2JBSNaYVWZKT/N/UjqicRZrsksrypg0Qh79n2msoNa40GdLaxTcbAAAAAKJgsgEAAAAgCiYbAAAAAKJgsgEAAAAgiqkPiIeN/hZemO51JRG4CRsPhU3+zN6ir4koFlWgxzdHq1/BvFM0OGxoq/2Abv++ZEgwI3bxORdf5GpHn1QB8ZeDZd/Az2xJqnH1DvjA1297tiSWC8/5gHjHfNVs0Bso+FB6LpsM6r1vmQ+n9e1STYbCRkRmumHRFDolGT5s7/Cf9cFyn3jhqkgDAmamjA0HFRWqrY2mfjYWPKzjsDhPn+LDvtnz/ee+UwS9i8Fxt3jIn/MzFfX+pH2ITR1pEtdfaS4hR1VRXbiJIHZTEP5WDxfqEE39MuJvKnpJ2/4059fw82Rm9ntRO0HUwgcYqZC9ujZVzRLD7asx1C6+2QAAAAAQBZMNAAAAAFEw2QAAAAAQBZMNAAAAAFHE7yA+ldKGwZUxtV4YIjp+t9HZqzW52OSDTOP7n5qmsUzc4187J7G84rpn3DpHn9wpXqkCk+8KlleKdXxAPJ/zoesH7vHh74ZcsE8O+f2v674HXa0kAp8f/dAiVyuWksG2XV1+DGZbRC1yGFxZkAx3lkVo7qHP/ql/3WfGY40IqH2N/mEOHfOTx+49e/aIF9bKuS5FV+Sh112pLJ7nUZg3z9UuOP+8xHJp2B9XfvLgZldrWOgD6OP7w+P6s34Qs9kCFaRPoU+cW0dFbeEKX5sfXJeoDtwlERovibB5sxpceJ2jrgNUslxRDxUIx6suudPWZvZDC/hmAwAAAEAUTDYAAAAARMFkAwAAAEAUTDYAAAAARFGdgHhOhHyUsKt4RXVyFJ0WZWZ8UNRUR+J6FYTwRn0obybq7lHdOQ+JmlovtDXVtrZ+z3fzNvMhxPFUHUB919ZKxX9+ikX/2Sj2Jcd29kW+0+qTBRGEHFLvT5r94RpRU6FC8fnfdUdisXtXih8H1Lsx/zCHnVuTD4K47Oq1bp3Hh/3xovDL2n8AyDFH/DG29xf+cuaBnuAcH15TmNn4bnW8VucDtV4dyYtjuWp0XQ6CzDJYLrp+t4n13OlPhKSz4oKvIv5+fervVwyWe8Q66jrxNFFT17XhA2RUyFu9ibMP32wAAAAAiILJBgAAAIAomGwAAAAAiILJBgAAAIAo4gfE9//K1xZeOMGNpQzXjKqEeNiJ0qzuA191oLzjj0T1u6L2oxRb8916zfpFTXQvTRUGV15xlZ4f+67fS9o7fC3oyj1Q8GOdL8J7fUNLXa3hlBsTy+NDqtOqClXeI2oAYslmk0HVfM4/ZKItG3ZO1r2Ta5fogH7YX86Uw0C46jZt/zQ1Q5rtXvjkxF63/HZfy4gwdU5cy4WrlcW1XUZ0+M6Ic1FW/e3D7amwtkzBi5r/TPlzYtoHD8yOB/T8//hmAwAAAEAUTDYAAAAARMFkAwAAAEAU1Wnql/an5oMVKymbn4h7VO2waswSDmSi99VjZrl/gq/zDbR0bSrN8aVlna60cJHPbOSDz08u5z94Z5+/zNXa29pdrevpL73dIAHUiHwmee94s8hnyHvmZ7wDvnRE1DC9dk3i3PHRvwgKaXIXZuma9KZdTzUlVK9T4wibSacd1+zDNxsAAAAAomCyAQAAACAKJhsAAAAAomCyAQAAACCKhvHx8fFUKzY0xB3JwtW+FjRwacj7oNu4argyIoI6+1XztTRhnUOidjTF6+pDyt1n0qLvfzXrUldZ+edXpHrllX+8JlkYLrp1bv13H5jIoGrGdO1/ZvW8D+Lt1NoxMLv8wsTyZWsvcOs88vAvXG187zMTGheqq9b2v5p1+uW+djBsZenPkbqWNugdPpQl7fbfTLn96ku7//HNBgAAAIAomGwAAAAAiILJBgAAAIAomGwAAAAAiCJ1QBwAAAAA3gm+2QAAAAAQBZMNAAAAAFEw2QAAAAAQBZMNAAAAAFEw2QAAAAAQBZMNAAAAAFEw2QAAAAAQBZMNAAAAAFEw2QAAAAAQxf8BSHZMhJh1DQcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#需要注意的是,\n",
    "# 如果是归一化后的图像,本质上来讲,让它显示出来是没什么意义的,\n",
    "# 因为PIL图像期待像素在[0,255]之间,归一化后必然导致图像失真\n",
    "plotsample(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型选择 此处选择ResNet和Vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(112)\n",
    "resnet18_=m.resnet18()\n",
    "vgg16_=m.vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(nn.Conv2d(3,64,kernel_size=3\n",
    "                                              ,stride=1,padding=1,bias=False)\n",
    "                                   ,resnet18_.bn1\n",
    "                                   ,resnet18_.relu) #删除池化层\n",
    "        \n",
    "        #后续的架构直接从经典架构中选\n",
    "        #对尺寸很小的数据集而言，我们的深度本来就不深，因此可以试着在特征图数量上有所增加（增加宽度）\n",
    "        self.block2 = resnet18_.layer2 #2个残差单元\n",
    "        self.block3 = resnet18_.layer3 #2个残差单元\n",
    "        #自适应平均池化+线性层，此处都与残差网络一致\n",
    "        self.avgpool = resnet18_.avgpool\n",
    "        #输出的线性层自己写，以确保输出的类别数量正确\n",
    "        self.fc = nn.Linear(in_features=256, out_features=10, bias=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0],256)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MyResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVgg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features=nn.Sequential(\n",
    "            *vgg16_.features[0:9],#这里解包表示这个东西从Sequential中取出来\n",
    "            nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2,2,padding=0,dilation=1,ceil_mode=True)\n",
    "        )\n",
    "        self.avgpool=vgg16_.avgpool\n",
    "        self.fc=nn.Sequential(\n",
    "            nn.Linear(7*7*128,out_features=4096,bias=True),\n",
    "            *vgg16_.classifier[1:6],\n",
    "            nn.Linear(in_features=4096,out_features=10,bias=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=self.avgpool(x)\n",
    "        x=x.view(x.shape[0],7*7*128)\n",
    "        x=self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MyResNet                                 [10, 10]                  --\n",
      "├─Sequential: 1-1                        [10, 64, 28, 28]          1,856\n",
      "├─Sequential: 1-2                        [10, 128, 14, 14]         525,568\n",
      "├─Sequential: 1-3                        [10, 256, 7, 7]           2,099,712\n",
      "├─AdaptiveAvgPool2d: 1-4                 [10, 256, 1, 1]           --\n",
      "├─Linear: 1-5                            [10, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 2,629,706\n",
      "Trainable params: 2,629,706\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.07\n",
      "==========================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 38.13\n",
      "Params size (MB): 10.52\n",
      "Estimated Total Size (MB): 48.75\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyVgg                                    [10, 10]                  --\n",
       "├─Sequential: 1-1                        [10, 128, 7, 7]           555,328\n",
       "├─AdaptiveAvgPool2d: 1-2                 [10, 128, 7, 7]           --\n",
       "├─Sequential: 1-3                        [10, 10]                  42,516,490\n",
       "==========================================================================================\n",
       "Total params: 43,071,818\n",
       "Trainable params: 43,071,818\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.74\n",
       "==========================================================================================\n",
       "Input size (MB): 0.09\n",
       "Forward/backward pass size (MB): 16.71\n",
       "Params size (MB): 172.29\n",
       "Estimated Total Size (MB): 189.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#单元测试\n",
    "from torchinfo import summary\n",
    "print(summary(MyResNet(),(10,3,28,28),depth=1,device=device))\n",
    "summary(MyVgg(),(10,3,28,28),depth=1,device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提前停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, patience=20, tolerance=0.0005):\n",
    "        self.patience = patience\n",
    "        self.tolerance=tolerance\n",
    "        self.counter=0#用来计数,判断当前是否已经累计patience次了\n",
    "        self.lowest_loss=None#历史最低损失\n",
    "        self.early_stop=False#True-提前结束，False-继续训练\n",
    "    \n",
    "    def __call__(self, val_loss):#val_loss当前Epoch损失\n",
    "        if self.lowest_loss is None:#第一次进来\n",
    "            self.lowest_loss=val_loss\n",
    "        elif self.lowest_loss-val_loss>self.tolerance:#如果比当前损失小,则替换最小值\n",
    "            self.lowest_loss=val_loss\n",
    "            self.counter=0\n",
    "        elif self.lowest_loss-val_loss<self.tolerance:#小于阈值,说明在最低损失的附近\n",
    "            self.counter+=1\n",
    "            print('Attention!! EarlyStopping counter: {} out of {}'.format(self.counter,self.patience))\n",
    "            if self.counter>=self.patience:#如果累计了patience次，则提前结束 \n",
    "                print('Early Stop Activate!')\n",
    "                self.early_stop=True\n",
    "        return self.early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把单词训练和测试的提取出来,fit_test()中只放一些有关数据等的记录\n",
    "def IterOnce(net, criterion, optimizer, x, y):\n",
    "    # 添加输入形状检查\n",
    "    if len(x.shape) != 4:\n",
    "        raise ValueError(f\"Expected 4D input, but got shape {x.shape}\")\n",
    "    sigma = net.forward(x)\n",
    "    loss = criterion(sigma, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    yhat = torch.max(sigma, 1)[1]\n",
    "    correct = torch.sum(yhat == y)\n",
    "    return correct, loss\n",
    "\n",
    "def TestOnce(net,criterion,x,y):\n",
    "    with torch.no_grad():\n",
    "        sigma=net.forward(x)\n",
    "        loss=criterion(sigma,y)\n",
    "        yhat=torch.max(sigma,1)[1]\n",
    "        correct=torch.sum(yhat==y)\n",
    "    return correct,loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_test(net,batchdata,testdata,criterion,optimizer,epochs,tolerance):\n",
    "    '''\n",
    "    对模型进行训练,并在每个epoch后输出训练集和测试集上的准确率--对模型的监控\n",
    "    保存模型\n",
    "    '''\n",
    "    SamplePerEpoch=batchdata.dataset.__len__()\n",
    "    allSamples=SamplePerEpoch*epochs\n",
    "    trainedSamples=0\n",
    "    trainLossList=[]\n",
    "    testLossList=[]#这两个list是用来画图的\n",
    "    early_stopping=EarlyStopping(tolerance=tolerance)\n",
    "    highestAcc=None\n",
    "    save_path='/data_disk/dyy/python_projects/bili_dif/learn/5.小型项目/state_dict'\n",
    "\n",
    "    #还得来个epoch\n",
    "    for epoch in range(1,1+epochs):\n",
    "        net.train()\n",
    "        correct_train=0\n",
    "        loss_train=0\n",
    "        for batch_idx,(x,y) in enumerate(batchdata):\n",
    "            x=x.to(device,non_blocking=True)\n",
    "            y=y.to(device,non_blocking=True).view(x.shape[0])#有的标签是列向量,需要转化为一维的张量\n",
    "            '''\n",
    "                #这时还没有经过softmax,其中的最大值就可以视为 y_hat,\n",
    "                考虑此时yhat的形状是什么--有Sample个样本,9中分类,那就是Sample*9\n",
    "                需要将9种分类中取出最大值,作为预测出的分类\n",
    "            '''\n",
    "            correct,loss=IterOnce(net,criterion,optimizer,x,y)\n",
    "            trainedSamples+=x.shape[0]\n",
    "            loss_train+=loss\n",
    "            correct_train+=correct#记录当前Epoch总共的正确样本数\n",
    "            \n",
    "            if((batch_idx+1)%125==0):\n",
    "                print('Train Epoch:{} [{}/{} ({:.0f}%)]'.format(\n",
    "                    epoch,\n",
    "                    trainedSamples,\n",
    "                    allSamples,\n",
    "                    trainedSamples/allSamples*100,\n",
    "                ))\n",
    "        \n",
    "\n",
    "        trainAccThisEpoch=float(correct_train*100)/SamplePerEpoch\n",
    "        trainLossThisEpoch=float(loss_train*100)/SamplePerEpoch#表示平均每个样本上的损失\n",
    "        trainLossList.append(trainLossThisEpoch)\n",
    "\n",
    "        #完成一次epoch后,需要清理GPU内存\n",
    "        del x,y,loss,correct_train,loss_train#清变量\n",
    "        gc.collect()#清缓存\n",
    "        torch.cuda.empty_cache()#\n",
    "\n",
    "\n",
    "        #这里就测一次,不需要再嵌套一个循环---因此这里的代码要和Epoch内层循环类比\n",
    "        net.eval()\n",
    "        loss_test=0\n",
    "        correct_test=0\n",
    "        TestSample=testdata.dataset.__len__()\n",
    "\n",
    "        for x,y in testdata:\n",
    "            x=x.to(device,non_blocking=True)\n",
    "            \n",
    "            y=y.to(device,non_blocking=True).view(x.shape[0])\n",
    "            correct,loss=TestOnce(net,criterion,x,y)\n",
    "                #算总loss和correct\n",
    "            loss_test+=loss\n",
    "            correct_test+=correct\n",
    "        testAccThisEpoch=float(correct_test*100)/TestSample\n",
    "        testLossThisEpoch=float(loss_test*100)/TestSample#平均每一个样本的损失\n",
    "        testLossList.append(testLossThisEpoch)\n",
    "        \n",
    "    \n",
    "        # del x,y,loss,correct_train,loss_train#清变量\n",
    "        # gc.collect()#清缓存\n",
    "        # torch.cuda.empty_cache()#\n",
    "\n",
    "\n",
    "        #对于每一个Epoch,打印训练和测试的结果\n",
    "        print('\\t Train Loss:{:.6f},Test Loss:{:.6f},Train Acc:{:.2f}%,Test Acc:{:.2f}%'.format(\n",
    "            trainLossThisEpoch,\n",
    "            testLossThisEpoch,\n",
    "            trainAccThisEpoch,\n",
    "            testAccThisEpoch\n",
    "        ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #如果测试机准确率新高,或者测试机Loss新低,那就保存权重\n",
    "        if highestAcc is None or testAccThisEpoch>highestAcc:\n",
    "            highestAcc=testAccThisEpoch\n",
    "            torch.save(net.state_dict(),os.path.join(save_path,'best.pth'))\n",
    "            print('Attention:Save Best Model!!!')\n",
    "\n",
    "\n",
    "        #提前停止\n",
    "        # early_stop=early_stopping(testLossThisEpoch)\n",
    "        # if early_stop is True:\n",
    "        #     print('Early Stopping')\n",
    "        #     break\n",
    "\n",
    "    print('Mission Complete!') \n",
    "    return trainLossList,testLossList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义整个执行流中需要的小组件,opt,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_procedure(net,epochs=100,bs=128,lr=0.001,alpha=0.99,gamma=0,wd=0,tolerance=0.00001):\n",
    "    torch.cuda.manual_seed(112)\n",
    "    torch.cuda.manual_seed_all(112)\n",
    "    torch.manual_seed(112)\n",
    "\n",
    "    #分割数据   \n",
    "    batchdata=DataLoader(\n",
    "    dataset=train,\n",
    "    batch_size=bs,\n",
    "    shuffle=True,\n",
    "    # num_workers=4,#控制线程数,但是对GPU来说,线程数不要太大\n",
    "    drop_last=False,\n",
    "    pin_memory=True,#将数据强制留在RAM中\n",
    "    )\n",
    "    \n",
    "    testdata=DataLoader(test,batch_size=bs,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        # num_workers=4\n",
    "                        pin_memory=True\n",
    "                    )\n",
    "    #损失函数,优化算法\n",
    "    criterion=nn.CrossEntropyLoss(reduction='sum')#损失函数,输出均值或者sum\n",
    "    optimizer=optim.RMSprop(net.parameters(),alpha=alpha,lr=lr,momentum=gamma,weight_decay=wd)\n",
    "\n",
    "    #训练与测试\n",
    "    trainloss,testloss=fit_test(net,batchdata,testdata,criterion,optimizer,epochs=epochs,tolerance=tolerance)\n",
    "    return trainloss,testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实例化\n",
    "#trainloss, testloss=full_procedure(xxx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绘图\n",
    "def plot_loss(trainloss, testloss):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(trainloss, label='train loss',color='red')\n",
    "    plt.plot(testloss, label='test loss',color='blue')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1 [16000/14651400 (0%)]\n",
      "Train Epoch:1 [32000/14651400 (0%)]\n",
      "Train Epoch:1 [48000/14651400 (0%)]\n",
      "Train Epoch:1 [64000/14651400 (0%)]\n",
      "\t Train Loss:114.975825,Test Loss:52.952534,Train Acc:60.95%,Test Acc:83.65%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:2 [89257/14651400 (1%)]\n",
      "Train Epoch:2 [105257/14651400 (1%)]\n",
      "Train Epoch:2 [121257/14651400 (1%)]\n",
      "Train Epoch:2 [137257/14651400 (1%)]\n",
      "\t Train Loss:40.904637,Test Loss:33.233688,Train Acc:87.19%,Test Acc:89.93%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:3 [162514/14651400 (1%)]\n",
      "Train Epoch:3 [178514/14651400 (1%)]\n",
      "Train Epoch:3 [194514/14651400 (1%)]\n",
      "Train Epoch:3 [210514/14651400 (1%)]\n",
      "\t Train Loss:34.040924,Test Loss:28.996399,Train Acc:89.61%,Test Acc:91.18%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:4 [235771/14651400 (2%)]\n",
      "Train Epoch:4 [251771/14651400 (2%)]\n",
      "Train Epoch:4 [267771/14651400 (2%)]\n",
      "Train Epoch:4 [283771/14651400 (2%)]\n",
      "\t Train Loss:30.578446,Test Loss:22.379809,Train Acc:90.68%,Test Acc:93.55%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:5 [309028/14651400 (2%)]\n",
      "Train Epoch:5 [325028/14651400 (2%)]\n",
      "Train Epoch:5 [341028/14651400 (2%)]\n",
      "Train Epoch:5 [357028/14651400 (2%)]\n",
      "\t Train Loss:28.093534,Test Loss:20.417690,Train Acc:91.46%,Test Acc:94.26%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:6 [382285/14651400 (3%)]\n",
      "Train Epoch:6 [398285/14651400 (3%)]\n",
      "Train Epoch:6 [414285/14651400 (3%)]\n",
      "Train Epoch:6 [430285/14651400 (3%)]\n",
      "\t Train Loss:25.999321,Test Loss:19.359605,Train Acc:92.21%,Test Acc:94.72%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:7 [455542/14651400 (3%)]\n",
      "Train Epoch:7 [471542/14651400 (3%)]\n",
      "Train Epoch:7 [487542/14651400 (3%)]\n",
      "Train Epoch:7 [503542/14651400 (3%)]\n",
      "\t Train Loss:24.505180,Test Loss:19.733964,Train Acc:92.67%,Test Acc:94.46%\n",
      "Train Epoch:8 [528799/14651400 (4%)]\n",
      "Train Epoch:8 [544799/14651400 (4%)]\n",
      "Train Epoch:8 [560799/14651400 (4%)]\n",
      "Train Epoch:8 [576799/14651400 (4%)]\n",
      "\t Train Loss:23.185801,Test Loss:17.571523,Train Acc:93.20%,Test Acc:95.31%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:9 [602056/14651400 (4%)]\n",
      "Train Epoch:9 [618056/14651400 (4%)]\n",
      "Train Epoch:9 [634056/14651400 (4%)]\n",
      "Train Epoch:9 [650056/14651400 (4%)]\n",
      "\t Train Loss:22.077080,Test Loss:18.962779,Train Acc:93.48%,Test Acc:94.78%\n",
      "Train Epoch:10 [675313/14651400 (5%)]\n",
      "Train Epoch:10 [691313/14651400 (5%)]\n",
      "Train Epoch:10 [707313/14651400 (5%)]\n",
      "Train Epoch:10 [723313/14651400 (5%)]\n",
      "\t Train Loss:21.251462,Test Loss:17.457947,Train Acc:93.62%,Test Acc:95.28%\n",
      "Train Epoch:11 [748570/14651400 (5%)]\n",
      "Train Epoch:11 [764570/14651400 (5%)]\n",
      "Train Epoch:11 [780570/14651400 (5%)]\n",
      "Train Epoch:11 [796570/14651400 (5%)]\n",
      "\t Train Loss:20.309457,Test Loss:15.087263,Train Acc:94.01%,Test Acc:96.02%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:12 [821827/14651400 (6%)]\n",
      "Train Epoch:12 [837827/14651400 (6%)]\n",
      "Train Epoch:12 [853827/14651400 (6%)]\n",
      "Train Epoch:12 [869827/14651400 (6%)]\n",
      "\t Train Loss:19.659877,Test Loss:16.115258,Train Acc:94.20%,Test Acc:95.68%\n",
      "Train Epoch:13 [895084/14651400 (6%)]\n",
      "Train Epoch:13 [911084/14651400 (6%)]\n",
      "Train Epoch:13 [927084/14651400 (6%)]\n",
      "Train Epoch:13 [943084/14651400 (6%)]\n",
      "\t Train Loss:18.935875,Test Loss:15.434629,Train Acc:94.42%,Test Acc:95.88%\n",
      "Train Epoch:14 [968341/14651400 (7%)]\n",
      "Train Epoch:14 [984341/14651400 (7%)]\n",
      "Train Epoch:14 [1000341/14651400 (7%)]\n",
      "Train Epoch:14 [1016341/14651400 (7%)]\n",
      "\t Train Loss:18.294165,Test Loss:16.389956,Train Acc:94.61%,Test Acc:95.56%\n",
      "Train Epoch:15 [1041598/14651400 (7%)]\n",
      "Train Epoch:15 [1057598/14651400 (7%)]\n",
      "Train Epoch:15 [1073598/14651400 (7%)]\n",
      "Train Epoch:15 [1089598/14651400 (7%)]\n",
      "\t Train Loss:17.529393,Test Loss:15.931174,Train Acc:94.87%,Test Acc:95.81%\n",
      "Train Epoch:16 [1114855/14651400 (8%)]\n",
      "Train Epoch:16 [1130855/14651400 (8%)]\n",
      "Train Epoch:16 [1146855/14651400 (8%)]\n",
      "Train Epoch:16 [1162855/14651400 (8%)]\n",
      "\t Train Loss:16.687189,Test Loss:14.370243,Train Acc:95.06%,Test Acc:96.17%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:17 [1188112/14651400 (8%)]\n",
      "Train Epoch:17 [1204112/14651400 (8%)]\n",
      "Train Epoch:17 [1220112/14651400 (8%)]\n",
      "Train Epoch:17 [1236112/14651400 (8%)]\n",
      "\t Train Loss:16.047944,Test Loss:14.836461,Train Acc:95.35%,Test Acc:96.14%\n",
      "Train Epoch:18 [1261369/14651400 (9%)]\n",
      "Train Epoch:18 [1277369/14651400 (9%)]\n",
      "Train Epoch:18 [1293369/14651400 (9%)]\n",
      "Train Epoch:18 [1309369/14651400 (9%)]\n",
      "\t Train Loss:15.779332,Test Loss:15.395824,Train Acc:95.48%,Test Acc:95.70%\n",
      "Train Epoch:19 [1334626/14651400 (9%)]\n",
      "Train Epoch:19 [1350626/14651400 (9%)]\n",
      "Train Epoch:19 [1366626/14651400 (9%)]\n",
      "Train Epoch:19 [1382626/14651400 (9%)]\n",
      "\t Train Loss:15.255138,Test Loss:14.321975,Train Acc:95.51%,Test Acc:96.36%\n",
      "Attention:Save Best Model!!!\n",
      "Train Epoch:20 [1407883/14651400 (10%)]\n",
      "Train Epoch:20 [1423883/14651400 (10%)]\n",
      "Train Epoch:20 [1439883/14651400 (10%)]\n",
      "Train Epoch:20 [1455883/14651400 (10%)]\n",
      "\t Train Loss:14.765553,Test Loss:14.294664,Train Acc:95.65%,Test Acc:96.30%\n",
      "Train Epoch:21 [1481140/14651400 (10%)]\n",
      "Train Epoch:21 [1497140/14651400 (10%)]\n",
      "Train Epoch:21 [1513140/14651400 (10%)]\n",
      "Train Epoch:21 [1529140/14651400 (10%)]\n",
      "\t Train Loss:13.925335,Test Loss:16.561128,Train Acc:95.87%,Test Acc:95.67%\n",
      "Train Epoch:22 [1554397/14651400 (11%)]\n",
      "Train Epoch:22 [1570397/14651400 (11%)]\n",
      "Train Epoch:22 [1586397/14651400 (11%)]\n",
      "Train Epoch:22 [1602397/14651400 (11%)]\n",
      "\t Train Loss:13.692520,Test Loss:15.372822,Train Acc:95.88%,Test Acc:96.07%\n",
      "Train Epoch:23 [1627654/14651400 (11%)]\n",
      "Train Epoch:23 [1643654/14651400 (11%)]\n",
      "Train Epoch:23 [1659654/14651400 (11%)]\n",
      "Train Epoch:23 [1675654/14651400 (11%)]\n",
      "\t Train Loss:12.900123,Test Loss:15.466371,Train Acc:96.21%,Test Acc:96.09%\n",
      "Train Epoch:24 [1700911/14651400 (12%)]\n",
      "Train Epoch:24 [1716911/14651400 (12%)]\n",
      "Train Epoch:24 [1732911/14651400 (12%)]\n",
      "Train Epoch:24 [1748911/14651400 (12%)]\n",
      "\t Train Loss:12.798340,Test Loss:14.976015,Train Acc:96.19%,Test Acc:96.09%\n",
      "Train Epoch:25 [1774168/14651400 (12%)]\n",
      "Train Epoch:25 [1790168/14651400 (12%)]\n",
      "Train Epoch:25 [1806168/14651400 (12%)]\n",
      "Train Epoch:25 [1822168/14651400 (12%)]\n",
      "\t Train Loss:12.325489,Test Loss:16.022130,Train Acc:96.39%,Test Acc:95.89%\n",
      "Train Epoch:26 [1847425/14651400 (13%)]\n",
      "Train Epoch:26 [1863425/14651400 (13%)]\n",
      "Train Epoch:26 [1879425/14651400 (13%)]\n",
      "Train Epoch:26 [1895425/14651400 (13%)]\n",
      "\t Train Loss:11.666163,Test Loss:16.360532,Train Acc:96.50%,Test Acc:95.81%\n",
      "Train Epoch:27 [1920682/14651400 (13%)]\n",
      "Train Epoch:27 [1936682/14651400 (13%)]\n",
      "Train Epoch:27 [1952682/14651400 (13%)]\n",
      "Train Epoch:27 [1968682/14651400 (13%)]\n",
      "\t Train Loss:11.509912,Test Loss:15.969845,Train Acc:96.54%,Test Acc:96.03%\n",
      "Train Epoch:28 [1993939/14651400 (14%)]\n",
      "Train Epoch:28 [2009939/14651400 (14%)]\n",
      "Train Epoch:28 [2025939/14651400 (14%)]\n",
      "Train Epoch:28 [2041939/14651400 (14%)]\n",
      "\t Train Loss:10.950878,Test Loss:17.545569,Train Acc:96.62%,Test Acc:95.44%\n",
      "Train Epoch:29 [2067196/14651400 (14%)]\n",
      "Train Epoch:29 [2083196/14651400 (14%)]\n",
      "Train Epoch:29 [2099196/14651400 (14%)]\n",
      "Train Epoch:29 [2115196/14651400 (14%)]\n",
      "\t Train Loss:10.688952,Test Loss:15.721710,Train Acc:96.68%,Test Acc:96.22%\n",
      "Train Epoch:30 [2140453/14651400 (15%)]\n",
      "Train Epoch:30 [2156453/14651400 (15%)]\n",
      "Train Epoch:30 [2172453/14651400 (15%)]\n",
      "Train Epoch:30 [2188453/14651400 (15%)]\n",
      "\t Train Loss:10.358345,Test Loss:16.990434,Train Acc:96.95%,Test Acc:95.67%\n",
      "Train Epoch:31 [2213710/14651400 (15%)]\n",
      "Train Epoch:31 [2229710/14651400 (15%)]\n",
      "Train Epoch:31 [2245710/14651400 (15%)]\n",
      "Train Epoch:31 [2261710/14651400 (15%)]\n",
      "\t Train Loss:10.050212,Test Loss:16.034482,Train Acc:96.95%,Test Acc:95.95%\n",
      "Train Epoch:32 [2286967/14651400 (16%)]\n",
      "Train Epoch:32 [2302967/14651400 (16%)]\n",
      "Train Epoch:32 [2318967/14651400 (16%)]\n",
      "Train Epoch:32 [2334967/14651400 (16%)]\n",
      "\t Train Loss:9.530521,Test Loss:16.828404,Train Acc:97.08%,Test Acc:95.87%\n",
      "Train Epoch:33 [2360224/14651400 (16%)]\n",
      "Train Epoch:33 [2376224/14651400 (16%)]\n",
      "Train Epoch:33 [2392224/14651400 (16%)]\n",
      "Train Epoch:33 [2408224/14651400 (16%)]\n",
      "\t Train Loss:9.167073,Test Loss:17.702461,Train Acc:97.25%,Test Acc:95.51%\n",
      "Train Epoch:34 [2433481/14651400 (17%)]\n",
      "Train Epoch:34 [2449481/14651400 (17%)]\n",
      "Train Epoch:34 [2465481/14651400 (17%)]\n",
      "Train Epoch:34 [2481481/14651400 (17%)]\n",
      "\t Train Loss:9.192417,Test Loss:16.889423,Train Acc:97.22%,Test Acc:95.74%\n",
      "Train Epoch:35 [2506738/14651400 (17%)]\n",
      "Train Epoch:35 [2522738/14651400 (17%)]\n",
      "Train Epoch:35 [2538738/14651400 (17%)]\n",
      "Train Epoch:35 [2554738/14651400 (17%)]\n",
      "\t Train Loss:8.682407,Test Loss:16.614585,Train Acc:97.37%,Test Acc:95.79%\n",
      "Train Epoch:36 [2579995/14651400 (18%)]\n",
      "Train Epoch:36 [2595995/14651400 (18%)]\n",
      "Train Epoch:36 [2611995/14651400 (18%)]\n",
      "Train Epoch:36 [2627995/14651400 (18%)]\n",
      "\t Train Loss:8.475407,Test Loss:16.543755,Train Acc:97.36%,Test Acc:96.00%\n",
      "Train Epoch:37 [2653252/14651400 (18%)]\n",
      "Train Epoch:37 [2669252/14651400 (18%)]\n",
      "Train Epoch:37 [2685252/14651400 (18%)]\n",
      "Train Epoch:37 [2701252/14651400 (18%)]\n",
      "\t Train Loss:8.135432,Test Loss:17.048905,Train Acc:97.43%,Test Acc:95.89%\n",
      "Train Epoch:38 [2726509/14651400 (19%)]\n",
      "Train Epoch:38 [2742509/14651400 (19%)]\n",
      "Train Epoch:38 [2758509/14651400 (19%)]\n",
      "Train Epoch:38 [2774509/14651400 (19%)]\n",
      "\t Train Loss:7.987908,Test Loss:17.666828,Train Acc:97.46%,Test Acc:95.76%\n",
      "Train Epoch:39 [2799766/14651400 (19%)]\n",
      "Train Epoch:39 [2815766/14651400 (19%)]\n",
      "Train Epoch:39 [2831766/14651400 (19%)]\n",
      "Train Epoch:39 [2847766/14651400 (19%)]\n",
      "\t Train Loss:7.766962,Test Loss:17.793259,Train Acc:97.54%,Test Acc:95.68%\n",
      "Train Epoch:40 [2873023/14651400 (20%)]\n",
      "Train Epoch:40 [2889023/14651400 (20%)]\n",
      "Train Epoch:40 [2905023/14651400 (20%)]\n",
      "Train Epoch:40 [2921023/14651400 (20%)]\n",
      "\t Train Loss:7.634362,Test Loss:17.869183,Train Acc:97.61%,Test Acc:95.74%\n",
      "Train Epoch:41 [2946280/14651400 (20%)]\n",
      "Train Epoch:41 [2962280/14651400 (20%)]\n",
      "Train Epoch:41 [2978280/14651400 (20%)]\n",
      "Train Epoch:41 [2994280/14651400 (20%)]\n",
      "\t Train Loss:7.102429,Test Loss:17.980598,Train Acc:97.80%,Test Acc:95.72%\n",
      "Train Epoch:42 [3019537/14651400 (21%)]\n",
      "Train Epoch:42 [3035537/14651400 (21%)]\n",
      "Train Epoch:42 [3051537/14651400 (21%)]\n",
      "Train Epoch:42 [3067537/14651400 (21%)]\n",
      "\t Train Loss:6.899089,Test Loss:18.352602,Train Acc:97.85%,Test Acc:96.04%\n",
      "Train Epoch:43 [3092794/14651400 (21%)]\n",
      "Train Epoch:43 [3108794/14651400 (21%)]\n",
      "Train Epoch:43 [3124794/14651400 (21%)]\n",
      "Train Epoch:43 [3140794/14651400 (21%)]\n",
      "\t Train Loss:6.790175,Test Loss:19.008015,Train Acc:97.84%,Test Acc:95.61%\n",
      "Train Epoch:44 [3166051/14651400 (22%)]\n",
      "Train Epoch:44 [3182051/14651400 (22%)]\n",
      "Train Epoch:44 [3198051/14651400 (22%)]\n",
      "Train Epoch:44 [3214051/14651400 (22%)]\n",
      "\t Train Loss:6.667224,Test Loss:18.392897,Train Acc:97.82%,Test Acc:96.07%\n",
      "Train Epoch:45 [3239308/14651400 (22%)]\n",
      "Train Epoch:45 [3255308/14651400 (22%)]\n",
      "Train Epoch:45 [3271308/14651400 (22%)]\n",
      "Train Epoch:45 [3287308/14651400 (22%)]\n",
      "\t Train Loss:6.406694,Test Loss:21.495203,Train Acc:97.96%,Test Acc:95.43%\n",
      "Train Epoch:46 [3312565/14651400 (23%)]\n",
      "Train Epoch:46 [3328565/14651400 (23%)]\n",
      "Train Epoch:46 [3344565/14651400 (23%)]\n",
      "Train Epoch:46 [3360565/14651400 (23%)]\n",
      "\t Train Loss:6.331206,Test Loss:19.575224,Train Acc:97.99%,Test Acc:95.73%\n",
      "Train Epoch:47 [3385822/14651400 (23%)]\n",
      "Train Epoch:47 [3401822/14651400 (23%)]\n",
      "Train Epoch:47 [3417822/14651400 (23%)]\n",
      "Train Epoch:47 [3433822/14651400 (23%)]\n",
      "\t Train Loss:6.021286,Test Loss:20.056199,Train Acc:98.00%,Test Acc:95.79%\n",
      "Train Epoch:48 [3459079/14651400 (24%)]\n",
      "Train Epoch:48 [3475079/14651400 (24%)]\n",
      "Train Epoch:48 [3491079/14651400 (24%)]\n",
      "Train Epoch:48 [3507079/14651400 (24%)]\n",
      "\t Train Loss:6.024852,Test Loss:20.245251,Train Acc:98.02%,Test Acc:95.77%\n",
      "Train Epoch:49 [3532336/14651400 (24%)]\n",
      "Train Epoch:49 [3548336/14651400 (24%)]\n",
      "Train Epoch:49 [3564336/14651400 (24%)]\n",
      "Train Epoch:49 [3580336/14651400 (24%)]\n",
      "\t Train Loss:5.611956,Test Loss:19.679411,Train Acc:98.15%,Test Acc:95.81%\n",
      "Train Epoch:50 [3605593/14651400 (25%)]\n",
      "Train Epoch:50 [3621593/14651400 (25%)]\n",
      "Train Epoch:50 [3637593/14651400 (25%)]\n",
      "Train Epoch:50 [3653593/14651400 (25%)]\n",
      "\t Train Loss:5.617856,Test Loss:20.540407,Train Acc:98.16%,Test Acc:95.59%\n",
      "Train Epoch:51 [3678850/14651400 (25%)]\n",
      "Train Epoch:51 [3694850/14651400 (25%)]\n",
      "Train Epoch:51 [3710850/14651400 (25%)]\n",
      "Train Epoch:51 [3726850/14651400 (25%)]\n",
      "\t Train Loss:5.795580,Test Loss:18.652217,Train Acc:98.12%,Test Acc:95.97%\n",
      "Train Epoch:52 [3752107/14651400 (26%)]\n",
      "Train Epoch:52 [3768107/14651400 (26%)]\n",
      "Train Epoch:52 [3784107/14651400 (26%)]\n",
      "Train Epoch:52 [3800107/14651400 (26%)]\n",
      "\t Train Loss:5.560294,Test Loss:20.750860,Train Acc:98.20%,Test Acc:95.61%\n",
      "Train Epoch:53 [3825364/14651400 (26%)]\n",
      "Train Epoch:53 [3841364/14651400 (26%)]\n",
      "Train Epoch:53 [3857364/14651400 (26%)]\n",
      "Train Epoch:53 [3873364/14651400 (26%)]\n",
      "\t Train Loss:5.243356,Test Loss:21.544916,Train Acc:98.30%,Test Acc:95.51%\n",
      "Train Epoch:54 [3898621/14651400 (27%)]\n",
      "Train Epoch:54 [3914621/14651400 (27%)]\n",
      "Train Epoch:54 [3930621/14651400 (27%)]\n",
      "Train Epoch:54 [3946621/14651400 (27%)]\n",
      "\t Train Loss:5.088811,Test Loss:19.800044,Train Acc:98.34%,Test Acc:95.96%\n",
      "Train Epoch:55 [3971878/14651400 (27%)]\n",
      "Train Epoch:55 [3987878/14651400 (27%)]\n",
      "Train Epoch:55 [4003878/14651400 (27%)]\n",
      "Train Epoch:55 [4019878/14651400 (27%)]\n",
      "\t Train Loss:4.944824,Test Loss:20.450143,Train Acc:98.32%,Test Acc:95.76%\n",
      "Train Epoch:56 [4045135/14651400 (28%)]\n",
      "Train Epoch:56 [4061135/14651400 (28%)]\n",
      "Train Epoch:56 [4077135/14651400 (28%)]\n",
      "Train Epoch:56 [4093135/14651400 (28%)]\n",
      "\t Train Loss:5.067242,Test Loss:20.989607,Train Acc:98.40%,Test Acc:95.69%\n",
      "Train Epoch:57 [4118392/14651400 (28%)]\n",
      "Train Epoch:57 [4134392/14651400 (28%)]\n",
      "Train Epoch:57 [4150392/14651400 (28%)]\n",
      "Train Epoch:57 [4166392/14651400 (28%)]\n",
      "\t Train Loss:4.970890,Test Loss:20.650442,Train Acc:98.40%,Test Acc:95.96%\n",
      "Train Epoch:58 [4191649/14651400 (29%)]\n",
      "Train Epoch:58 [4207649/14651400 (29%)]\n",
      "Train Epoch:58 [4223649/14651400 (29%)]\n",
      "Train Epoch:58 [4239649/14651400 (29%)]\n",
      "\t Train Loss:4.612553,Test Loss:20.208176,Train Acc:98.50%,Test Acc:95.94%\n",
      "Train Epoch:59 [4264906/14651400 (29%)]\n",
      "Train Epoch:59 [4280906/14651400 (29%)]\n",
      "Train Epoch:59 [4296906/14651400 (29%)]\n",
      "Train Epoch:59 [4312906/14651400 (29%)]\n",
      "\t Train Loss:4.603188,Test Loss:20.811957,Train Acc:98.47%,Test Acc:95.70%\n",
      "Train Epoch:60 [4338163/14651400 (30%)]\n",
      "Train Epoch:60 [4354163/14651400 (30%)]\n",
      "Train Epoch:60 [4370163/14651400 (30%)]\n",
      "Train Epoch:60 [4386163/14651400 (30%)]\n",
      "\t Train Loss:4.421533,Test Loss:22.597704,Train Acc:98.54%,Test Acc:95.70%\n",
      "Train Epoch:61 [4411420/14651400 (30%)]\n",
      "Train Epoch:61 [4427420/14651400 (30%)]\n",
      "Train Epoch:61 [4443420/14651400 (30%)]\n",
      "Train Epoch:61 [4459420/14651400 (30%)]\n",
      "\t Train Loss:4.437796,Test Loss:21.915150,Train Acc:98.51%,Test Acc:95.79%\n",
      "Train Epoch:62 [4484677/14651400 (31%)]\n",
      "Train Epoch:62 [4500677/14651400 (31%)]\n",
      "Train Epoch:62 [4516677/14651400 (31%)]\n",
      "Train Epoch:62 [4532677/14651400 (31%)]\n",
      "\t Train Loss:4.310602,Test Loss:21.220479,Train Acc:98.53%,Test Acc:95.67%\n",
      "Train Epoch:63 [4557934/14651400 (31%)]\n",
      "Train Epoch:63 [4573934/14651400 (31%)]\n",
      "Train Epoch:63 [4589934/14651400 (31%)]\n",
      "Train Epoch:63 [4605934/14651400 (31%)]\n",
      "\t Train Loss:4.236885,Test Loss:22.310457,Train Acc:98.59%,Test Acc:95.59%\n",
      "Train Epoch:64 [4631191/14651400 (32%)]\n",
      "Train Epoch:64 [4647191/14651400 (32%)]\n",
      "Train Epoch:64 [4663191/14651400 (32%)]\n",
      "Train Epoch:64 [4679191/14651400 (32%)]\n",
      "\t Train Loss:4.346061,Test Loss:21.368522,Train Acc:98.53%,Test Acc:95.88%\n",
      "Train Epoch:65 [4704448/14651400 (32%)]\n",
      "Train Epoch:65 [4720448/14651400 (32%)]\n",
      "Train Epoch:65 [4736448/14651400 (32%)]\n",
      "Train Epoch:65 [4752448/14651400 (32%)]\n",
      "\t Train Loss:4.133979,Test Loss:21.741213,Train Acc:98.64%,Test Acc:95.87%\n",
      "Train Epoch:66 [4777705/14651400 (33%)]\n",
      "Train Epoch:66 [4793705/14651400 (33%)]\n",
      "Train Epoch:66 [4809705/14651400 (33%)]\n",
      "Train Epoch:66 [4825705/14651400 (33%)]\n",
      "\t Train Loss:4.107441,Test Loss:21.869216,Train Acc:98.63%,Test Acc:95.55%\n",
      "Train Epoch:67 [4850962/14651400 (33%)]\n",
      "Train Epoch:67 [4866962/14651400 (33%)]\n",
      "Train Epoch:67 [4882962/14651400 (33%)]\n",
      "Train Epoch:67 [4898962/14651400 (33%)]\n",
      "\t Train Loss:4.046730,Test Loss:24.822082,Train Acc:98.69%,Test Acc:95.25%\n",
      "Train Epoch:68 [4924219/14651400 (34%)]\n",
      "Train Epoch:68 [4940219/14651400 (34%)]\n",
      "Train Epoch:68 [4956219/14651400 (34%)]\n",
      "Train Epoch:68 [4972219/14651400 (34%)]\n",
      "\t Train Loss:3.878211,Test Loss:21.718769,Train Acc:98.67%,Test Acc:95.83%\n",
      "Train Epoch:69 [4997476/14651400 (34%)]\n",
      "Train Epoch:69 [5013476/14651400 (34%)]\n",
      "Train Epoch:69 [5029476/14651400 (34%)]\n",
      "Train Epoch:69 [5045476/14651400 (34%)]\n",
      "\t Train Loss:3.990730,Test Loss:20.946290,Train Acc:98.67%,Test Acc:96.04%\n",
      "Train Epoch:70 [5070733/14651400 (35%)]\n",
      "Train Epoch:70 [5086733/14651400 (35%)]\n",
      "Train Epoch:70 [5102733/14651400 (35%)]\n",
      "Train Epoch:70 [5118733/14651400 (35%)]\n",
      "\t Train Loss:3.896177,Test Loss:22.156444,Train Acc:98.66%,Test Acc:95.76%\n",
      "Train Epoch:71 [5143990/14651400 (35%)]\n",
      "Train Epoch:71 [5159990/14651400 (35%)]\n",
      "Train Epoch:71 [5175990/14651400 (35%)]\n",
      "Train Epoch:71 [5191990/14651400 (35%)]\n",
      "\t Train Loss:3.608456,Test Loss:23.579208,Train Acc:98.76%,Test Acc:95.74%\n",
      "Train Epoch:72 [5217247/14651400 (36%)]\n",
      "Train Epoch:72 [5233247/14651400 (36%)]\n",
      "Train Epoch:72 [5249247/14651400 (36%)]\n",
      "Train Epoch:72 [5265247/14651400 (36%)]\n",
      "\t Train Loss:3.555188,Test Loss:23.847327,Train Acc:98.82%,Test Acc:95.79%\n",
      "Train Epoch:73 [5290504/14651400 (36%)]\n",
      "Train Epoch:73 [5306504/14651400 (36%)]\n",
      "Train Epoch:73 [5322504/14651400 (36%)]\n",
      "Train Epoch:73 [5338504/14651400 (36%)]\n",
      "\t Train Loss:3.621551,Test Loss:23.970572,Train Acc:98.79%,Test Acc:95.59%\n",
      "Train Epoch:74 [5363761/14651400 (37%)]\n",
      "Train Epoch:74 [5379761/14651400 (37%)]\n",
      "Train Epoch:74 [5395761/14651400 (37%)]\n",
      "Train Epoch:74 [5411761/14651400 (37%)]\n",
      "\t Train Loss:3.675102,Test Loss:25.314788,Train Acc:98.76%,Test Acc:95.73%\n",
      "Train Epoch:75 [5437018/14651400 (37%)]\n",
      "Train Epoch:75 [5453018/14651400 (37%)]\n",
      "Train Epoch:75 [5469018/14651400 (37%)]\n",
      "Train Epoch:75 [5485018/14651400 (37%)]\n",
      "\t Train Loss:3.787781,Test Loss:23.612832,Train Acc:98.75%,Test Acc:95.74%\n",
      "Train Epoch:76 [5510275/14651400 (38%)]\n",
      "Train Epoch:76 [5526275/14651400 (38%)]\n",
      "Train Epoch:76 [5542275/14651400 (38%)]\n",
      "Train Epoch:76 [5558275/14651400 (38%)]\n",
      "\t Train Loss:3.463995,Test Loss:23.015138,Train Acc:98.83%,Test Acc:95.88%\n",
      "Train Epoch:77 [5583532/14651400 (38%)]\n",
      "Train Epoch:77 [5599532/14651400 (38%)]\n",
      "Train Epoch:77 [5615532/14651400 (38%)]\n",
      "Train Epoch:77 [5631532/14651400 (38%)]\n",
      "\t Train Loss:3.543346,Test Loss:22.165820,Train Acc:98.80%,Test Acc:95.93%\n",
      "Train Epoch:78 [5656789/14651400 (39%)]\n",
      "Train Epoch:78 [5672789/14651400 (39%)]\n",
      "Train Epoch:78 [5688789/14651400 (39%)]\n",
      "Train Epoch:78 [5704789/14651400 (39%)]\n",
      "\t Train Loss:3.261425,Test Loss:23.154164,Train Acc:98.94%,Test Acc:96.04%\n",
      "Train Epoch:79 [5730046/14651400 (39%)]\n",
      "Train Epoch:79 [5746046/14651400 (39%)]\n",
      "Train Epoch:79 [5762046/14651400 (39%)]\n",
      "Train Epoch:79 [5778046/14651400 (39%)]\n",
      "\t Train Loss:3.399458,Test Loss:23.211406,Train Acc:98.81%,Test Acc:95.71%\n",
      "Train Epoch:80 [5803303/14651400 (40%)]\n",
      "Train Epoch:80 [5819303/14651400 (40%)]\n",
      "Train Epoch:80 [5835303/14651400 (40%)]\n",
      "Train Epoch:80 [5851303/14651400 (40%)]\n",
      "\t Train Loss:3.294444,Test Loss:21.926782,Train Acc:98.87%,Test Acc:96.25%\n",
      "Train Epoch:81 [5876560/14651400 (40%)]\n",
      "Train Epoch:81 [5892560/14651400 (40%)]\n",
      "Train Epoch:81 [5908560/14651400 (40%)]\n",
      "Train Epoch:81 [5924560/14651400 (40%)]\n",
      "\t Train Loss:3.033082,Test Loss:23.545816,Train Acc:98.96%,Test Acc:95.95%\n",
      "Train Epoch:82 [5949817/14651400 (41%)]\n",
      "Train Epoch:82 [5965817/14651400 (41%)]\n",
      "Train Epoch:82 [5981817/14651400 (41%)]\n",
      "Train Epoch:82 [5997817/14651400 (41%)]\n",
      "\t Train Loss:2.966877,Test Loss:24.167323,Train Acc:98.96%,Test Acc:95.81%\n",
      "Train Epoch:83 [6023074/14651400 (41%)]\n",
      "Train Epoch:83 [6039074/14651400 (41%)]\n",
      "Train Epoch:83 [6055074/14651400 (41%)]\n",
      "Train Epoch:83 [6071074/14651400 (41%)]\n",
      "\t Train Loss:3.194064,Test Loss:22.777168,Train Acc:98.93%,Test Acc:95.99%\n",
      "Train Epoch:84 [6096331/14651400 (42%)]\n",
      "Train Epoch:84 [6112331/14651400 (42%)]\n",
      "Train Epoch:84 [6128331/14651400 (42%)]\n",
      "Train Epoch:84 [6144331/14651400 (42%)]\n",
      "\t Train Loss:3.019797,Test Loss:22.347034,Train Acc:99.01%,Test Acc:96.11%\n",
      "Train Epoch:85 [6169588/14651400 (42%)]\n",
      "Train Epoch:85 [6185588/14651400 (42%)]\n",
      "Train Epoch:85 [6201588/14651400 (42%)]\n",
      "Train Epoch:85 [6217588/14651400 (42%)]\n",
      "\t Train Loss:3.187996,Test Loss:23.529437,Train Acc:98.93%,Test Acc:95.87%\n",
      "Train Epoch:86 [6242845/14651400 (43%)]\n",
      "Train Epoch:86 [6258845/14651400 (43%)]\n",
      "Train Epoch:86 [6274845/14651400 (43%)]\n",
      "Train Epoch:86 [6290845/14651400 (43%)]\n",
      "\t Train Loss:3.035637,Test Loss:22.341265,Train Acc:98.97%,Test Acc:95.92%\n",
      "Train Epoch:87 [6316102/14651400 (43%)]\n",
      "Train Epoch:87 [6332102/14651400 (43%)]\n",
      "Train Epoch:87 [6348102/14651400 (43%)]\n",
      "Train Epoch:87 [6364102/14651400 (43%)]\n",
      "\t Train Loss:3.012008,Test Loss:24.458724,Train Acc:98.98%,Test Acc:95.68%\n",
      "Train Epoch:88 [6389359/14651400 (44%)]\n",
      "Train Epoch:88 [6405359/14651400 (44%)]\n",
      "Train Epoch:88 [6421359/14651400 (44%)]\n",
      "Train Epoch:88 [6437359/14651400 (44%)]\n",
      "\t Train Loss:2.867252,Test Loss:24.262878,Train Acc:99.02%,Test Acc:95.72%\n",
      "Train Epoch:89 [6462616/14651400 (44%)]\n",
      "Train Epoch:89 [6478616/14651400 (44%)]\n",
      "Train Epoch:89 [6494616/14651400 (44%)]\n",
      "Train Epoch:89 [6510616/14651400 (44%)]\n",
      "\t Train Loss:2.858883,Test Loss:23.378894,Train Acc:99.01%,Test Acc:96.01%\n",
      "Train Epoch:90 [6535873/14651400 (45%)]\n",
      "Train Epoch:90 [6551873/14651400 (45%)]\n",
      "Train Epoch:90 [6567873/14651400 (45%)]\n",
      "Train Epoch:90 [6583873/14651400 (45%)]\n",
      "\t Train Loss:2.843487,Test Loss:24.565052,Train Acc:99.08%,Test Acc:95.67%\n",
      "Train Epoch:91 [6609130/14651400 (45%)]\n",
      "Train Epoch:91 [6625130/14651400 (45%)]\n",
      "Train Epoch:91 [6641130/14651400 (45%)]\n",
      "Train Epoch:91 [6657130/14651400 (45%)]\n",
      "\t Train Loss:2.935631,Test Loss:25.634680,Train Acc:99.03%,Test Acc:95.61%\n",
      "Train Epoch:92 [6682387/14651400 (46%)]\n",
      "Train Epoch:92 [6698387/14651400 (46%)]\n",
      "Train Epoch:92 [6714387/14651400 (46%)]\n",
      "Train Epoch:92 [6730387/14651400 (46%)]\n",
      "\t Train Loss:2.857109,Test Loss:26.217127,Train Acc:99.10%,Test Acc:95.38%\n",
      "Train Epoch:93 [6755644/14651400 (46%)]\n",
      "Train Epoch:93 [6771644/14651400 (46%)]\n",
      "Train Epoch:93 [6787644/14651400 (46%)]\n",
      "Train Epoch:93 [6803644/14651400 (46%)]\n",
      "\t Train Loss:2.657455,Test Loss:25.316613,Train Acc:99.11%,Test Acc:95.84%\n",
      "Train Epoch:94 [6828901/14651400 (47%)]\n",
      "Train Epoch:94 [6844901/14651400 (47%)]\n",
      "Train Epoch:94 [6860901/14651400 (47%)]\n",
      "Train Epoch:94 [6876901/14651400 (47%)]\n",
      "\t Train Loss:2.846953,Test Loss:24.339844,Train Acc:99.07%,Test Acc:95.82%\n",
      "Train Epoch:95 [6902158/14651400 (47%)]\n",
      "Train Epoch:95 [6918158/14651400 (47%)]\n",
      "Train Epoch:95 [6934158/14651400 (47%)]\n",
      "Train Epoch:95 [6950158/14651400 (47%)]\n",
      "\t Train Loss:2.717015,Test Loss:25.690914,Train Acc:99.03%,Test Acc:95.86%\n",
      "Train Epoch:96 [6975415/14651400 (48%)]\n",
      "Train Epoch:96 [6991415/14651400 (48%)]\n",
      "Train Epoch:96 [7007415/14651400 (48%)]\n",
      "Train Epoch:96 [7023415/14651400 (48%)]\n",
      "\t Train Loss:2.546099,Test Loss:26.191778,Train Acc:99.12%,Test Acc:95.71%\n",
      "Train Epoch:97 [7048672/14651400 (48%)]\n",
      "Train Epoch:97 [7064672/14651400 (48%)]\n",
      "Train Epoch:97 [7080672/14651400 (48%)]\n",
      "Train Epoch:97 [7096672/14651400 (48%)]\n",
      "\t Train Loss:2.636410,Test Loss:26.342814,Train Acc:99.10%,Test Acc:95.75%\n",
      "Train Epoch:98 [7121929/14651400 (49%)]\n",
      "Train Epoch:98 [7137929/14651400 (49%)]\n",
      "Train Epoch:98 [7153929/14651400 (49%)]\n",
      "Train Epoch:98 [7169929/14651400 (49%)]\n",
      "\t Train Loss:2.616262,Test Loss:23.986305,Train Acc:99.09%,Test Acc:96.00%\n",
      "Train Epoch:99 [7195186/14651400 (49%)]\n",
      "Train Epoch:99 [7211186/14651400 (49%)]\n",
      "Train Epoch:99 [7227186/14651400 (49%)]\n",
      "Train Epoch:99 [7243186/14651400 (49%)]\n",
      "\t Train Loss:2.606784,Test Loss:27.446878,Train Acc:99.15%,Test Acc:95.65%\n",
      "Train Epoch:100 [7268443/14651400 (50%)]\n",
      "Train Epoch:100 [7284443/14651400 (50%)]\n",
      "Train Epoch:100 [7300443/14651400 (50%)]\n",
      "Train Epoch:100 [7316443/14651400 (50%)]\n",
      "\t Train Loss:2.581073,Test Loss:23.905429,Train Acc:99.10%,Test Acc:96.01%\n",
      "Train Epoch:101 [7341700/14651400 (50%)]\n",
      "Train Epoch:101 [7357700/14651400 (50%)]\n",
      "Train Epoch:101 [7373700/14651400 (50%)]\n",
      "Train Epoch:101 [7389700/14651400 (50%)]\n",
      "\t Train Loss:2.581741,Test Loss:27.615941,Train Acc:99.13%,Test Acc:95.73%\n",
      "Train Epoch:102 [7414957/14651400 (51%)]\n",
      "Train Epoch:102 [7430957/14651400 (51%)]\n",
      "Train Epoch:102 [7446957/14651400 (51%)]\n",
      "Train Epoch:102 [7462957/14651400 (51%)]\n",
      "\t Train Loss:2.583507,Test Loss:25.285925,Train Acc:99.13%,Test Acc:96.04%\n",
      "Train Epoch:103 [7488214/14651400 (51%)]\n",
      "Train Epoch:103 [7504214/14651400 (51%)]\n",
      "Train Epoch:103 [7520214/14651400 (51%)]\n",
      "Train Epoch:103 [7536214/14651400 (51%)]\n",
      "\t Train Loss:2.613811,Test Loss:26.514360,Train Acc:99.13%,Test Acc:95.89%\n",
      "Train Epoch:104 [7561471/14651400 (52%)]\n",
      "Train Epoch:104 [7577471/14651400 (52%)]\n",
      "Train Epoch:104 [7593471/14651400 (52%)]\n",
      "Train Epoch:104 [7609471/14651400 (52%)]\n",
      "\t Train Loss:2.547800,Test Loss:27.241508,Train Acc:99.17%,Test Acc:95.30%\n",
      "Train Epoch:105 [7634728/14651400 (52%)]\n",
      "Train Epoch:105 [7650728/14651400 (52%)]\n",
      "Train Epoch:105 [7666728/14651400 (52%)]\n",
      "Train Epoch:105 [7682728/14651400 (52%)]\n",
      "\t Train Loss:2.258160,Test Loss:24.484027,Train Acc:99.20%,Test Acc:96.05%\n",
      "Train Epoch:106 [7707985/14651400 (53%)]\n",
      "Train Epoch:106 [7723985/14651400 (53%)]\n",
      "Train Epoch:106 [7739985/14651400 (53%)]\n",
      "Train Epoch:106 [7755985/14651400 (53%)]\n",
      "\t Train Loss:2.392905,Test Loss:24.322961,Train Acc:99.19%,Test Acc:96.12%\n",
      "Train Epoch:107 [7781242/14651400 (53%)]\n",
      "Train Epoch:107 [7797242/14651400 (53%)]\n",
      "Train Epoch:107 [7813242/14651400 (53%)]\n",
      "Train Epoch:107 [7829242/14651400 (53%)]\n",
      "\t Train Loss:2.357138,Test Loss:26.543238,Train Acc:99.20%,Test Acc:95.56%\n",
      "Train Epoch:108 [7854499/14651400 (54%)]\n",
      "Train Epoch:108 [7870499/14651400 (54%)]\n",
      "Train Epoch:108 [7886499/14651400 (54%)]\n",
      "Train Epoch:108 [7902499/14651400 (54%)]\n",
      "\t Train Loss:2.309904,Test Loss:28.533113,Train Acc:99.23%,Test Acc:95.40%\n",
      "Train Epoch:109 [7927756/14651400 (54%)]\n",
      "Train Epoch:109 [7943756/14651400 (54%)]\n",
      "Train Epoch:109 [7959756/14651400 (54%)]\n",
      "Train Epoch:109 [7975756/14651400 (54%)]\n",
      "\t Train Loss:2.465965,Test Loss:24.392570,Train Acc:99.17%,Test Acc:96.02%\n",
      "Train Epoch:110 [8001013/14651400 (55%)]\n",
      "Train Epoch:110 [8017013/14651400 (55%)]\n",
      "Train Epoch:110 [8033013/14651400 (55%)]\n",
      "Train Epoch:110 [8049013/14651400 (55%)]\n",
      "\t Train Loss:2.192565,Test Loss:24.699240,Train Acc:99.23%,Test Acc:96.02%\n",
      "Train Epoch:111 [8074270/14651400 (55%)]\n",
      "Train Epoch:111 [8090270/14651400 (55%)]\n",
      "Train Epoch:111 [8106270/14651400 (55%)]\n",
      "Train Epoch:111 [8122270/14651400 (55%)]\n",
      "\t Train Loss:2.132018,Test Loss:24.471122,Train Acc:99.27%,Test Acc:96.05%\n",
      "Train Epoch:112 [8147527/14651400 (56%)]\n",
      "Train Epoch:112 [8163527/14651400 (56%)]\n",
      "Train Epoch:112 [8179527/14651400 (56%)]\n",
      "Train Epoch:112 [8195527/14651400 (56%)]\n",
      "\t Train Loss:2.219460,Test Loss:25.014686,Train Acc:99.23%,Test Acc:96.14%\n",
      "Train Epoch:113 [8220784/14651400 (56%)]\n",
      "Train Epoch:113 [8236784/14651400 (56%)]\n",
      "Train Epoch:113 [8252784/14651400 (56%)]\n",
      "Train Epoch:113 [8268784/14651400 (56%)]\n",
      "\t Train Loss:2.351276,Test Loss:26.468363,Train Acc:99.20%,Test Acc:95.53%\n",
      "Train Epoch:114 [8294041/14651400 (57%)]\n",
      "Train Epoch:114 [8310041/14651400 (57%)]\n",
      "Train Epoch:114 [8326041/14651400 (57%)]\n",
      "Train Epoch:114 [8342041/14651400 (57%)]\n",
      "\t Train Loss:2.274706,Test Loss:25.670912,Train Acc:99.24%,Test Acc:95.91%\n",
      "Train Epoch:115 [8367298/14651400 (57%)]\n",
      "Train Epoch:115 [8383298/14651400 (57%)]\n",
      "Train Epoch:115 [8399298/14651400 (57%)]\n",
      "Train Epoch:115 [8415298/14651400 (57%)]\n",
      "\t Train Loss:2.299358,Test Loss:25.336226,Train Acc:99.25%,Test Acc:95.77%\n",
      "Train Epoch:116 [8440555/14651400 (58%)]\n",
      "Train Epoch:116 [8456555/14651400 (58%)]\n",
      "Train Epoch:116 [8472555/14651400 (58%)]\n",
      "Train Epoch:116 [8488555/14651400 (58%)]\n",
      "\t Train Loss:2.177924,Test Loss:26.058008,Train Acc:99.26%,Test Acc:95.84%\n",
      "Train Epoch:117 [8513812/14651400 (58%)]\n",
      "Train Epoch:117 [8529812/14651400 (58%)]\n",
      "Train Epoch:117 [8545812/14651400 (58%)]\n",
      "Train Epoch:117 [8561812/14651400 (58%)]\n",
      "\t Train Loss:2.168276,Test Loss:26.306351,Train Acc:99.28%,Test Acc:95.80%\n",
      "Train Epoch:118 [8587069/14651400 (59%)]\n",
      "Train Epoch:118 [8603069/14651400 (59%)]\n",
      "Train Epoch:118 [8619069/14651400 (59%)]\n",
      "Train Epoch:118 [8635069/14651400 (59%)]\n",
      "\t Train Loss:2.096962,Test Loss:26.371281,Train Acc:99.28%,Test Acc:95.85%\n",
      "Train Epoch:119 [8660326/14651400 (59%)]\n",
      "Train Epoch:119 [8676326/14651400 (59%)]\n",
      "Train Epoch:119 [8692326/14651400 (59%)]\n",
      "Train Epoch:119 [8708326/14651400 (59%)]\n",
      "\t Train Loss:2.123864,Test Loss:25.956678,Train Acc:99.31%,Test Acc:95.95%\n",
      "Train Epoch:120 [8733583/14651400 (60%)]\n",
      "Train Epoch:120 [8749583/14651400 (60%)]\n",
      "Train Epoch:120 [8765583/14651400 (60%)]\n",
      "Train Epoch:120 [8781583/14651400 (60%)]\n",
      "\t Train Loss:2.294852,Test Loss:26.175668,Train Acc:99.23%,Test Acc:95.89%\n",
      "Train Epoch:121 [8806840/14651400 (60%)]\n",
      "Train Epoch:121 [8822840/14651400 (60%)]\n",
      "Train Epoch:121 [8838840/14651400 (60%)]\n",
      "Train Epoch:121 [8854840/14651400 (60%)]\n",
      "\t Train Loss:2.000288,Test Loss:25.902048,Train Acc:99.28%,Test Acc:95.92%\n",
      "Train Epoch:122 [8880097/14651400 (61%)]\n",
      "Train Epoch:122 [8896097/14651400 (61%)]\n",
      "Train Epoch:122 [8912097/14651400 (61%)]\n",
      "Train Epoch:122 [8928097/14651400 (61%)]\n",
      "\t Train Loss:2.204122,Test Loss:25.814063,Train Acc:99.27%,Test Acc:95.87%\n",
      "Train Epoch:123 [8953354/14651400 (61%)]\n",
      "Train Epoch:123 [8969354/14651400 (61%)]\n",
      "Train Epoch:123 [8985354/14651400 (61%)]\n",
      "Train Epoch:123 [9001354/14651400 (61%)]\n",
      "\t Train Loss:2.170430,Test Loss:28.221585,Train Acc:99.24%,Test Acc:95.64%\n",
      "Train Epoch:124 [9026611/14651400 (62%)]\n",
      "Train Epoch:124 [9042611/14651400 (62%)]\n",
      "Train Epoch:124 [9058611/14651400 (62%)]\n",
      "Train Epoch:124 [9074611/14651400 (62%)]\n",
      "\t Train Loss:1.924698,Test Loss:27.375910,Train Acc:99.37%,Test Acc:95.90%\n",
      "Train Epoch:125 [9099868/14651400 (62%)]\n",
      "Train Epoch:125 [9115868/14651400 (62%)]\n",
      "Train Epoch:125 [9131868/14651400 (62%)]\n",
      "Train Epoch:125 [9147868/14651400 (62%)]\n",
      "\t Train Loss:2.090352,Test Loss:25.320327,Train Acc:99.27%,Test Acc:96.10%\n",
      "Train Epoch:126 [9173125/14651400 (63%)]\n",
      "Train Epoch:126 [9189125/14651400 (63%)]\n",
      "Train Epoch:126 [9205125/14651400 (63%)]\n",
      "Train Epoch:126 [9221125/14651400 (63%)]\n",
      "\t Train Loss:1.939658,Test Loss:29.276035,Train Acc:99.36%,Test Acc:95.53%\n",
      "Train Epoch:127 [9246382/14651400 (63%)]\n",
      "Train Epoch:127 [9262382/14651400 (63%)]\n",
      "Train Epoch:127 [9278382/14651400 (63%)]\n",
      "Train Epoch:127 [9294382/14651400 (63%)]\n",
      "\t Train Loss:2.026729,Test Loss:26.819237,Train Acc:99.31%,Test Acc:95.80%\n",
      "Train Epoch:128 [9319639/14651400 (64%)]\n",
      "Train Epoch:128 [9335639/14651400 (64%)]\n",
      "Train Epoch:128 [9351639/14651400 (64%)]\n",
      "Train Epoch:128 [9367639/14651400 (64%)]\n",
      "\t Train Loss:2.024593,Test Loss:27.131737,Train Acc:99.31%,Test Acc:95.95%\n",
      "Train Epoch:129 [9392896/14651400 (64%)]\n",
      "Train Epoch:129 [9408896/14651400 (64%)]\n",
      "Train Epoch:129 [9424896/14651400 (64%)]\n",
      "Train Epoch:129 [9440896/14651400 (64%)]\n",
      "\t Train Loss:2.096396,Test Loss:27.508778,Train Acc:99.32%,Test Acc:95.81%\n",
      "Train Epoch:130 [9466153/14651400 (65%)]\n",
      "Train Epoch:130 [9482153/14651400 (65%)]\n",
      "Train Epoch:130 [9498153/14651400 (65%)]\n",
      "Train Epoch:130 [9514153/14651400 (65%)]\n",
      "\t Train Loss:1.901719,Test Loss:26.478466,Train Acc:99.38%,Test Acc:95.89%\n",
      "Train Epoch:131 [9539410/14651400 (65%)]\n",
      "Train Epoch:131 [9555410/14651400 (65%)]\n",
      "Train Epoch:131 [9571410/14651400 (65%)]\n",
      "Train Epoch:131 [9587410/14651400 (65%)]\n",
      "\t Train Loss:1.929399,Test Loss:26.960573,Train Acc:99.38%,Test Acc:95.94%\n",
      "Train Epoch:132 [9612667/14651400 (66%)]\n",
      "Train Epoch:132 [9628667/14651400 (66%)]\n",
      "Train Epoch:132 [9644667/14651400 (66%)]\n",
      "Train Epoch:132 [9660667/14651400 (66%)]\n",
      "\t Train Loss:1.844763,Test Loss:28.146380,Train Acc:99.34%,Test Acc:95.61%\n",
      "Train Epoch:133 [9685924/14651400 (66%)]\n",
      "Train Epoch:133 [9701924/14651400 (66%)]\n",
      "Train Epoch:133 [9717924/14651400 (66%)]\n",
      "Train Epoch:133 [9733924/14651400 (66%)]\n",
      "\t Train Loss:1.868087,Test Loss:28.997532,Train Acc:99.37%,Test Acc:95.56%\n",
      "Train Epoch:134 [9759181/14651400 (67%)]\n",
      "Train Epoch:134 [9775181/14651400 (67%)]\n",
      "Train Epoch:134 [9791181/14651400 (67%)]\n",
      "Train Epoch:134 [9807181/14651400 (67%)]\n",
      "\t Train Loss:1.982408,Test Loss:28.552918,Train Acc:99.33%,Test Acc:95.85%\n",
      "Train Epoch:135 [9832438/14651400 (67%)]\n",
      "Train Epoch:135 [9848438/14651400 (67%)]\n",
      "Train Epoch:135 [9864438/14651400 (67%)]\n",
      "Train Epoch:135 [9880438/14651400 (67%)]\n",
      "\t Train Loss:1.948130,Test Loss:26.420302,Train Acc:99.33%,Test Acc:95.84%\n",
      "Train Epoch:136 [9905695/14651400 (68%)]\n",
      "Train Epoch:136 [9921695/14651400 (68%)]\n",
      "Train Epoch:136 [9937695/14651400 (68%)]\n",
      "Train Epoch:136 [9953695/14651400 (68%)]\n",
      "\t Train Loss:1.768920,Test Loss:28.131262,Train Acc:99.40%,Test Acc:95.85%\n",
      "Train Epoch:137 [9978952/14651400 (68%)]\n",
      "Train Epoch:137 [9994952/14651400 (68%)]\n",
      "Train Epoch:137 [10010952/14651400 (68%)]\n",
      "Train Epoch:137 [10026952/14651400 (68%)]\n",
      "\t Train Loss:1.831791,Test Loss:28.065736,Train Acc:99.34%,Test Acc:95.72%\n",
      "Train Epoch:138 [10052209/14651400 (69%)]\n",
      "Train Epoch:138 [10068209/14651400 (69%)]\n",
      "Train Epoch:138 [10084209/14651400 (69%)]\n",
      "Train Epoch:138 [10100209/14651400 (69%)]\n",
      "\t Train Loss:1.922469,Test Loss:27.022537,Train Acc:99.36%,Test Acc:96.02%\n",
      "Train Epoch:139 [10125466/14651400 (69%)]\n",
      "Train Epoch:139 [10141466/14651400 (69%)]\n",
      "Train Epoch:139 [10157466/14651400 (69%)]\n",
      "Train Epoch:139 [10173466/14651400 (69%)]\n",
      "\t Train Loss:1.710525,Test Loss:30.012958,Train Acc:99.42%,Test Acc:95.59%\n",
      "Train Epoch:140 [10198723/14651400 (70%)]\n",
      "Train Epoch:140 [10214723/14651400 (70%)]\n",
      "Train Epoch:140 [10230723/14651400 (70%)]\n",
      "Train Epoch:140 [10246723/14651400 (70%)]\n",
      "\t Train Loss:1.850790,Test Loss:28.908920,Train Acc:99.41%,Test Acc:95.79%\n",
      "Train Epoch:141 [10271980/14651400 (70%)]\n",
      "Train Epoch:141 [10287980/14651400 (70%)]\n",
      "Train Epoch:141 [10303980/14651400 (70%)]\n",
      "Train Epoch:141 [10319980/14651400 (70%)]\n",
      "\t Train Loss:1.827788,Test Loss:27.171347,Train Acc:99.41%,Test Acc:96.14%\n",
      "Train Epoch:142 [10345237/14651400 (71%)]\n",
      "Train Epoch:142 [10361237/14651400 (71%)]\n",
      "Train Epoch:142 [10377237/14651400 (71%)]\n",
      "Train Epoch:142 [10393237/14651400 (71%)]\n",
      "\t Train Loss:1.751849,Test Loss:26.641314,Train Acc:99.42%,Test Acc:96.13%\n",
      "Train Epoch:143 [10418494/14651400 (71%)]\n",
      "Train Epoch:143 [10434494/14651400 (71%)]\n",
      "Train Epoch:143 [10450494/14651400 (71%)]\n",
      "Train Epoch:143 [10466494/14651400 (71%)]\n",
      "\t Train Loss:1.777837,Test Loss:27.060464,Train Acc:99.42%,Test Acc:96.00%\n",
      "Train Epoch:144 [10491751/14651400 (72%)]\n",
      "Train Epoch:144 [10507751/14651400 (72%)]\n",
      "Train Epoch:144 [10523751/14651400 (72%)]\n",
      "Train Epoch:144 [10539751/14651400 (72%)]\n",
      "\t Train Loss:1.760815,Test Loss:27.967833,Train Acc:99.45%,Test Acc:95.99%\n",
      "Train Epoch:145 [10565008/14651400 (72%)]\n",
      "Train Epoch:145 [10581008/14651400 (72%)]\n",
      "Train Epoch:145 [10597008/14651400 (72%)]\n",
      "Train Epoch:145 [10613008/14651400 (72%)]\n",
      "\t Train Loss:1.694627,Test Loss:29.439404,Train Acc:99.44%,Test Acc:95.82%\n",
      "Train Epoch:146 [10638265/14651400 (73%)]\n",
      "Train Epoch:146 [10654265/14651400 (73%)]\n",
      "Train Epoch:146 [10670265/14651400 (73%)]\n",
      "Train Epoch:146 [10686265/14651400 (73%)]\n",
      "\t Train Loss:1.682481,Test Loss:29.477071,Train Acc:99.43%,Test Acc:95.79%\n",
      "Train Epoch:147 [10711522/14651400 (73%)]\n",
      "Train Epoch:147 [10727522/14651400 (73%)]\n",
      "Train Epoch:147 [10743522/14651400 (73%)]\n",
      "Train Epoch:147 [10759522/14651400 (73%)]\n",
      "\t Train Loss:1.795854,Test Loss:30.132337,Train Acc:99.39%,Test Acc:95.72%\n",
      "Train Epoch:148 [10784779/14651400 (74%)]\n",
      "Train Epoch:148 [10800779/14651400 (74%)]\n",
      "Train Epoch:148 [10816779/14651400 (74%)]\n",
      "Train Epoch:148 [10832779/14651400 (74%)]\n",
      "\t Train Loss:1.810043,Test Loss:27.761896,Train Acc:99.40%,Test Acc:95.95%\n",
      "Train Epoch:149 [10858036/14651400 (74%)]\n",
      "Train Epoch:149 [10874036/14651400 (74%)]\n",
      "Train Epoch:149 [10890036/14651400 (74%)]\n",
      "Train Epoch:149 [10906036/14651400 (74%)]\n",
      "\t Train Loss:1.713744,Test Loss:26.195048,Train Acc:99.45%,Test Acc:96.12%\n",
      "Train Epoch:150 [10931293/14651400 (75%)]\n",
      "Train Epoch:150 [10947293/14651400 (75%)]\n",
      "Train Epoch:150 [10963293/14651400 (75%)]\n",
      "Train Epoch:150 [10979293/14651400 (75%)]\n",
      "\t Train Loss:1.687222,Test Loss:29.551552,Train Acc:99.45%,Test Acc:96.02%\n",
      "Train Epoch:151 [11004550/14651400 (75%)]\n",
      "Train Epoch:151 [11020550/14651400 (75%)]\n",
      "Train Epoch:151 [11036550/14651400 (75%)]\n",
      "Train Epoch:151 [11052550/14651400 (75%)]\n",
      "\t Train Loss:1.475846,Test Loss:28.945521,Train Acc:99.47%,Test Acc:95.82%\n",
      "Train Epoch:152 [11077807/14651400 (76%)]\n",
      "Train Epoch:152 [11093807/14651400 (76%)]\n",
      "Train Epoch:152 [11109807/14651400 (76%)]\n",
      "Train Epoch:152 [11125807/14651400 (76%)]\n",
      "\t Train Loss:1.670210,Test Loss:28.775879,Train Acc:99.44%,Test Acc:95.99%\n",
      "Train Epoch:153 [11151064/14651400 (76%)]\n",
      "Train Epoch:153 [11167064/14651400 (76%)]\n",
      "Train Epoch:153 [11183064/14651400 (76%)]\n",
      "Train Epoch:153 [11199064/14651400 (76%)]\n",
      "\t Train Loss:1.732972,Test Loss:28.652433,Train Acc:99.44%,Test Acc:95.97%\n",
      "Train Epoch:154 [11224321/14651400 (77%)]\n",
      "Train Epoch:154 [11240321/14651400 (77%)]\n",
      "Train Epoch:154 [11256321/14651400 (77%)]\n",
      "Train Epoch:154 [11272321/14651400 (77%)]\n",
      "\t Train Loss:1.612607,Test Loss:29.049850,Train Acc:99.46%,Test Acc:95.59%\n",
      "Train Epoch:155 [11297578/14651400 (77%)]\n",
      "Train Epoch:155 [11313578/14651400 (77%)]\n",
      "Train Epoch:155 [11329578/14651400 (77%)]\n",
      "Train Epoch:155 [11345578/14651400 (77%)]\n",
      "\t Train Loss:1.599198,Test Loss:29.102741,Train Acc:99.46%,Test Acc:95.84%\n",
      "Train Epoch:156 [11370835/14651400 (78%)]\n",
      "Train Epoch:156 [11386835/14651400 (78%)]\n",
      "Train Epoch:156 [11402835/14651400 (78%)]\n",
      "Train Epoch:156 [11418835/14651400 (78%)]\n",
      "\t Train Loss:1.820692,Test Loss:29.300808,Train Acc:99.41%,Test Acc:95.71%\n",
      "Train Epoch:157 [11444092/14651400 (78%)]\n",
      "Train Epoch:157 [11460092/14651400 (78%)]\n",
      "Train Epoch:157 [11476092/14651400 (78%)]\n",
      "Train Epoch:157 [11492092/14651400 (78%)]\n",
      "\t Train Loss:1.508705,Test Loss:30.577986,Train Acc:99.49%,Test Acc:95.83%\n",
      "Train Epoch:158 [11517349/14651400 (79%)]\n",
      "Train Epoch:158 [11533349/14651400 (79%)]\n",
      "Train Epoch:158 [11549349/14651400 (79%)]\n",
      "Train Epoch:158 [11565349/14651400 (79%)]\n",
      "\t Train Loss:1.565872,Test Loss:31.127370,Train Acc:99.48%,Test Acc:95.77%\n",
      "Train Epoch:159 [11590606/14651400 (79%)]\n",
      "Train Epoch:159 [11606606/14651400 (79%)]\n",
      "Train Epoch:159 [11622606/14651400 (79%)]\n",
      "Train Epoch:159 [11638606/14651400 (79%)]\n",
      "\t Train Loss:1.657709,Test Loss:28.244500,Train Acc:99.43%,Test Acc:95.82%\n",
      "Train Epoch:160 [11663863/14651400 (80%)]\n",
      "Train Epoch:160 [11679863/14651400 (80%)]\n",
      "Train Epoch:160 [11695863/14651400 (80%)]\n",
      "Train Epoch:160 [11711863/14651400 (80%)]\n",
      "\t Train Loss:1.713597,Test Loss:28.451113,Train Acc:99.43%,Test Acc:95.79%\n",
      "Train Epoch:161 [11737120/14651400 (80%)]\n",
      "Train Epoch:161 [11753120/14651400 (80%)]\n",
      "Train Epoch:161 [11769120/14651400 (80%)]\n",
      "Train Epoch:161 [11785120/14651400 (80%)]\n",
      "\t Train Loss:1.501317,Test Loss:29.155895,Train Acc:99.49%,Test Acc:95.85%\n",
      "Train Epoch:162 [11810377/14651400 (81%)]\n",
      "Train Epoch:162 [11826377/14651400 (81%)]\n",
      "Train Epoch:162 [11842377/14651400 (81%)]\n",
      "Train Epoch:162 [11858377/14651400 (81%)]\n",
      "\t Train Loss:1.372775,Test Loss:28.530342,Train Acc:99.53%,Test Acc:95.99%\n",
      "Train Epoch:163 [11883634/14651400 (81%)]\n",
      "Train Epoch:163 [11899634/14651400 (81%)]\n",
      "Train Epoch:163 [11915634/14651400 (81%)]\n",
      "Train Epoch:163 [11931634/14651400 (81%)]\n",
      "\t Train Loss:1.569024,Test Loss:28.634099,Train Acc:99.46%,Test Acc:95.84%\n",
      "Train Epoch:164 [11956891/14651400 (82%)]\n",
      "Train Epoch:164 [11972891/14651400 (82%)]\n",
      "Train Epoch:164 [11988891/14651400 (82%)]\n",
      "Train Epoch:164 [12004891/14651400 (82%)]\n",
      "\t Train Loss:1.446857,Test Loss:30.566250,Train Acc:99.47%,Test Acc:95.87%\n",
      "Train Epoch:165 [12030148/14651400 (82%)]\n",
      "Train Epoch:165 [12046148/14651400 (82%)]\n",
      "Train Epoch:165 [12062148/14651400 (82%)]\n",
      "Train Epoch:165 [12078148/14651400 (82%)]\n",
      "\t Train Loss:1.559021,Test Loss:30.410591,Train Acc:99.46%,Test Acc:95.74%\n",
      "Train Epoch:166 [12103405/14651400 (83%)]\n",
      "Train Epoch:166 [12119405/14651400 (83%)]\n",
      "Train Epoch:166 [12135405/14651400 (83%)]\n",
      "Train Epoch:166 [12151405/14651400 (83%)]\n",
      "\t Train Loss:1.553674,Test Loss:29.924552,Train Acc:99.47%,Test Acc:95.73%\n",
      "Train Epoch:167 [12176662/14651400 (83%)]\n",
      "Train Epoch:167 [12192662/14651400 (83%)]\n",
      "Train Epoch:167 [12208662/14651400 (83%)]\n",
      "Train Epoch:167 [12224662/14651400 (83%)]\n",
      "\t Train Loss:1.539452,Test Loss:29.076065,Train Acc:99.51%,Test Acc:95.92%\n",
      "Train Epoch:168 [12249919/14651400 (84%)]\n",
      "Train Epoch:168 [12265919/14651400 (84%)]\n",
      "Train Epoch:168 [12281919/14651400 (84%)]\n",
      "Train Epoch:168 [12297919/14651400 (84%)]\n",
      "\t Train Loss:1.456079,Test Loss:29.121701,Train Acc:99.50%,Test Acc:95.74%\n",
      "Train Epoch:169 [12323176/14651400 (84%)]\n",
      "Train Epoch:169 [12339176/14651400 (84%)]\n",
      "Train Epoch:169 [12355176/14651400 (84%)]\n",
      "Train Epoch:169 [12371176/14651400 (84%)]\n",
      "\t Train Loss:1.584998,Test Loss:29.496495,Train Acc:99.46%,Test Acc:96.01%\n",
      "Train Epoch:170 [12396433/14651400 (85%)]\n",
      "Train Epoch:170 [12412433/14651400 (85%)]\n",
      "Train Epoch:170 [12428433/14651400 (85%)]\n",
      "Train Epoch:170 [12444433/14651400 (85%)]\n",
      "\t Train Loss:1.602511,Test Loss:31.254816,Train Acc:99.48%,Test Acc:95.80%\n",
      "Train Epoch:171 [12469690/14651400 (85%)]\n",
      "Train Epoch:171 [12485690/14651400 (85%)]\n",
      "Train Epoch:171 [12501690/14651400 (85%)]\n",
      "Train Epoch:171 [12517690/14651400 (85%)]\n",
      "\t Train Loss:1.458493,Test Loss:31.574956,Train Acc:99.51%,Test Acc:95.69%\n",
      "Train Epoch:172 [12542947/14651400 (86%)]\n",
      "Train Epoch:172 [12558947/14651400 (86%)]\n",
      "Train Epoch:172 [12574947/14651400 (86%)]\n",
      "Train Epoch:172 [12590947/14651400 (86%)]\n",
      "\t Train Loss:1.489912,Test Loss:30.343726,Train Acc:99.52%,Test Acc:95.92%\n",
      "Train Epoch:173 [12616204/14651400 (86%)]\n",
      "Train Epoch:173 [12632204/14651400 (86%)]\n",
      "Train Epoch:173 [12648204/14651400 (86%)]\n",
      "Train Epoch:173 [12664204/14651400 (86%)]\n",
      "\t Train Loss:1.472681,Test Loss:29.636181,Train Acc:99.49%,Test Acc:95.91%\n",
      "Train Epoch:174 [12689461/14651400 (87%)]\n",
      "Train Epoch:174 [12705461/14651400 (87%)]\n",
      "Train Epoch:174 [12721461/14651400 (87%)]\n",
      "Train Epoch:174 [12737461/14651400 (87%)]\n",
      "\t Train Loss:1.442193,Test Loss:29.456421,Train Acc:99.52%,Test Acc:95.76%\n",
      "Train Epoch:175 [12762718/14651400 (87%)]\n",
      "Train Epoch:175 [12778718/14651400 (87%)]\n",
      "Train Epoch:175 [12794718/14651400 (87%)]\n",
      "Train Epoch:175 [12810718/14651400 (87%)]\n",
      "\t Train Loss:1.377004,Test Loss:29.981033,Train Acc:99.52%,Test Acc:96.02%\n",
      "Train Epoch:176 [12835975/14651400 (88%)]\n",
      "Train Epoch:176 [12851975/14651400 (88%)]\n",
      "Train Epoch:176 [12867975/14651400 (88%)]\n",
      "Train Epoch:176 [12883975/14651400 (88%)]\n",
      "\t Train Loss:1.587451,Test Loss:30.940780,Train Acc:99.50%,Test Acc:95.85%\n",
      "Train Epoch:177 [12909232/14651400 (88%)]\n",
      "Train Epoch:177 [12925232/14651400 (88%)]\n",
      "Train Epoch:177 [12941232/14651400 (88%)]\n",
      "Train Epoch:177 [12957232/14651400 (88%)]\n",
      "\t Train Loss:1.432850,Test Loss:29.338492,Train Acc:99.52%,Test Acc:95.91%\n",
      "Train Epoch:178 [12982489/14651400 (89%)]\n",
      "Train Epoch:178 [12998489/14651400 (89%)]\n",
      "Train Epoch:178 [13014489/14651400 (89%)]\n",
      "Train Epoch:178 [13030489/14651400 (89%)]\n",
      "\t Train Loss:1.454401,Test Loss:29.566233,Train Acc:99.51%,Test Acc:95.99%\n",
      "Train Epoch:179 [13055746/14651400 (89%)]\n",
      "Train Epoch:179 [13071746/14651400 (89%)]\n",
      "Train Epoch:179 [13087746/14651400 (89%)]\n",
      "Train Epoch:179 [13103746/14651400 (89%)]\n",
      "\t Train Loss:1.424143,Test Loss:31.063561,Train Acc:99.54%,Test Acc:95.84%\n",
      "Train Epoch:180 [13129003/14651400 (90%)]\n",
      "Train Epoch:180 [13145003/14651400 (90%)]\n",
      "Train Epoch:180 [13161003/14651400 (90%)]\n",
      "Train Epoch:180 [13177003/14651400 (90%)]\n",
      "\t Train Loss:1.507052,Test Loss:29.305782,Train Acc:99.52%,Test Acc:95.90%\n",
      "Train Epoch:181 [13202260/14651400 (90%)]\n",
      "Train Epoch:181 [13218260/14651400 (90%)]\n",
      "Train Epoch:181 [13234260/14651400 (90%)]\n",
      "Train Epoch:181 [13250260/14651400 (90%)]\n",
      "\t Train Loss:1.332598,Test Loss:29.169100,Train Acc:99.57%,Test Acc:95.91%\n",
      "Train Epoch:182 [13275517/14651400 (91%)]\n",
      "Train Epoch:182 [13291517/14651400 (91%)]\n",
      "Train Epoch:182 [13307517/14651400 (91%)]\n",
      "Train Epoch:182 [13323517/14651400 (91%)]\n",
      "\t Train Loss:1.498706,Test Loss:29.980783,Train Acc:99.51%,Test Acc:95.89%\n",
      "Train Epoch:183 [13348774/14651400 (91%)]\n",
      "Train Epoch:183 [13364774/14651400 (91%)]\n",
      "Train Epoch:183 [13380774/14651400 (91%)]\n",
      "Train Epoch:183 [13396774/14651400 (91%)]\n",
      "\t Train Loss:1.321888,Test Loss:31.555261,Train Acc:99.54%,Test Acc:95.99%\n",
      "Train Epoch:184 [13422031/14651400 (92%)]\n",
      "Train Epoch:184 [13438031/14651400 (92%)]\n",
      "Train Epoch:184 [13454031/14651400 (92%)]\n",
      "Train Epoch:184 [13470031/14651400 (92%)]\n",
      "\t Train Loss:1.390636,Test Loss:30.853428,Train Acc:99.55%,Test Acc:95.98%\n",
      "Train Epoch:185 [13495288/14651400 (92%)]\n",
      "Train Epoch:185 [13511288/14651400 (92%)]\n",
      "Train Epoch:185 [13527288/14651400 (92%)]\n",
      "Train Epoch:185 [13543288/14651400 (92%)]\n",
      "\t Train Loss:1.368533,Test Loss:32.555180,Train Acc:99.55%,Test Acc:95.78%\n",
      "Train Epoch:186 [13568545/14651400 (93%)]\n",
      "Train Epoch:186 [13584545/14651400 (93%)]\n",
      "Train Epoch:186 [13600545/14651400 (93%)]\n",
      "Train Epoch:186 [13616545/14651400 (93%)]\n",
      "\t Train Loss:1.392767,Test Loss:30.818634,Train Acc:99.54%,Test Acc:95.76%\n",
      "Train Epoch:187 [13641802/14651400 (93%)]\n",
      "Train Epoch:187 [13657802/14651400 (93%)]\n",
      "Train Epoch:187 [13673802/14651400 (93%)]\n",
      "Train Epoch:187 [13689802/14651400 (93%)]\n",
      "\t Train Loss:1.243290,Test Loss:31.867163,Train Acc:99.61%,Test Acc:95.91%\n",
      "Train Epoch:188 [13715059/14651400 (94%)]\n",
      "Train Epoch:188 [13731059/14651400 (94%)]\n",
      "Train Epoch:188 [13747059/14651400 (94%)]\n",
      "Train Epoch:188 [13763059/14651400 (94%)]\n",
      "\t Train Loss:1.439916,Test Loss:29.942191,Train Acc:99.51%,Test Acc:95.77%\n",
      "Train Epoch:189 [13788316/14651400 (94%)]\n",
      "Train Epoch:189 [13804316/14651400 (94%)]\n",
      "Train Epoch:189 [13820316/14651400 (94%)]\n",
      "Train Epoch:189 [13836316/14651400 (94%)]\n",
      "\t Train Loss:1.284686,Test Loss:30.114751,Train Acc:99.53%,Test Acc:95.93%\n",
      "Train Epoch:190 [13861573/14651400 (95%)]\n",
      "Train Epoch:190 [13877573/14651400 (95%)]\n",
      "Train Epoch:190 [13893573/14651400 (95%)]\n",
      "Train Epoch:190 [13909573/14651400 (95%)]\n",
      "\t Train Loss:1.289742,Test Loss:30.029382,Train Acc:99.59%,Test Acc:95.92%\n",
      "Train Epoch:191 [13934830/14651400 (95%)]\n",
      "Train Epoch:191 [13950830/14651400 (95%)]\n",
      "Train Epoch:191 [13966830/14651400 (95%)]\n",
      "Train Epoch:191 [13982830/14651400 (95%)]\n",
      "\t Train Loss:1.339915,Test Loss:29.642207,Train Acc:99.56%,Test Acc:95.89%\n",
      "Train Epoch:192 [14008087/14651400 (96%)]\n",
      "Train Epoch:192 [14024087/14651400 (96%)]\n",
      "Train Epoch:192 [14040087/14651400 (96%)]\n",
      "Train Epoch:192 [14056087/14651400 (96%)]\n",
      "\t Train Loss:1.423799,Test Loss:29.144567,Train Acc:99.51%,Test Acc:95.99%\n",
      "Train Epoch:193 [14081344/14651400 (96%)]\n",
      "Train Epoch:193 [14097344/14651400 (96%)]\n",
      "Train Epoch:193 [14113344/14651400 (96%)]\n",
      "Train Epoch:193 [14129344/14651400 (96%)]\n",
      "\t Train Loss:1.508890,Test Loss:30.107764,Train Acc:99.52%,Test Acc:96.05%\n",
      "Train Epoch:194 [14154601/14651400 (97%)]\n",
      "Train Epoch:194 [14170601/14651400 (97%)]\n",
      "Train Epoch:194 [14186601/14651400 (97%)]\n",
      "Train Epoch:194 [14202601/14651400 (97%)]\n",
      "\t Train Loss:1.289296,Test Loss:31.014758,Train Acc:99.53%,Test Acc:95.97%\n",
      "Train Epoch:195 [14227858/14651400 (97%)]\n",
      "Train Epoch:195 [14243858/14651400 (97%)]\n",
      "Train Epoch:195 [14259858/14651400 (97%)]\n",
      "Train Epoch:195 [14275858/14651400 (97%)]\n",
      "\t Train Loss:1.212232,Test Loss:31.339476,Train Acc:99.59%,Test Acc:95.81%\n",
      "Train Epoch:196 [14301115/14651400 (98%)]\n",
      "Train Epoch:196 [14317115/14651400 (98%)]\n",
      "Train Epoch:196 [14333115/14651400 (98%)]\n",
      "Train Epoch:196 [14349115/14651400 (98%)]\n",
      "\t Train Loss:1.264833,Test Loss:29.719254,Train Acc:99.58%,Test Acc:96.10%\n",
      "Train Epoch:197 [14374372/14651400 (98%)]\n",
      "Train Epoch:197 [14390372/14651400 (98%)]\n",
      "Train Epoch:197 [14406372/14651400 (98%)]\n",
      "Train Epoch:197 [14422372/14651400 (98%)]\n",
      "\t Train Loss:1.379219,Test Loss:30.674725,Train Acc:99.53%,Test Acc:96.07%\n",
      "Train Epoch:198 [14447629/14651400 (99%)]\n",
      "Train Epoch:198 [14463629/14651400 (99%)]\n",
      "Train Epoch:198 [14479629/14651400 (99%)]\n",
      "Train Epoch:198 [14495629/14651400 (99%)]\n",
      "\t Train Loss:1.251183,Test Loss:30.326574,Train Acc:99.58%,Test Acc:95.89%\n",
      "Train Epoch:199 [14520886/14651400 (99%)]\n",
      "Train Epoch:199 [14536886/14651400 (99%)]\n",
      "Train Epoch:199 [14552886/14651400 (99%)]\n",
      "Train Epoch:199 [14568886/14651400 (99%)]\n",
      "\t Train Loss:1.252205,Test Loss:32.194950,Train Acc:99.56%,Test Acc:95.81%\n",
      "Train Epoch:200 [14594143/14651400 (100%)]\n",
      "Train Epoch:200 [14610143/14651400 (100%)]\n",
      "Train Epoch:200 [14626143/14651400 (100%)]\n",
      "Train Epoch:200 [14642143/14651400 (100%)]\n",
      "\t Train Loss:1.308335,Test Loss:30.387746,Train Acc:99.55%,Test Acc:95.81%\n",
      "Mission Complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 确保所有随机种子一致\n",
    "torch.manual_seed(112)\n",
    "random.seed(112)\n",
    "np.random.seed(112)\n",
    "torch.cuda.manual_seed(112)\n",
    "torch.cuda.manual_seed_all(112)\n",
    "\n",
    "# 实例化 ResNet18 模型（而不是函数）\n",
    "resnet18_ = m.resnet18()  # 修正：实例化模型\n",
    "net = MyResNet().to(device)  # 创建你的自定义 ResNet 模型并移到 GPU 上\n",
    "\n",
    "# 调用 full_procedure 训练模型\n",
    "trainloss, testloss = full_procedure(net, epochs=200, bs=128, lr=0.001, alpha=0.99, gamma=0, wd=0, tolerance=0.00001)\n",
    "\n",
    "# 绘制损失曲线\n",
    "plot_loss(trainloss, testloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Flux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
